<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>ebxeax</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="ebxeax">
<meta property="og:url" content="http://ebxeax.github.io/page/5/index.html">
<meta property="og:site_name" content="ebxeax">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="ebx">
<meta property="article:tag" content="blog">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="ebxeax" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">ebxeax</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://ebxeax.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-2023-01-11-torch-repeat" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2023-01-11-torch-repeat/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.760Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x, y = torch.arange(<span class="number">12</span>), torch.arange(<span class="number">24</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x, y</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),
 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape, y.shape</span><br></pre></td></tr></table></figure>




<pre><code>(torch.Size([12]), torch.Size([24]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.numel(), y.numel()</span><br></pre></td></tr></table></figure>




<pre><code>(12, 24)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.reshape(<span class="number">3</span>, <span class="number">4</span>), y.reshape(<span class="number">6</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[ 0,  1,  2,  3],
         [ 4,  5,  6,  7],
         [ 8,  9, 10, 11]]),
 tensor([[ 0,  1,  2,  3],
         [ 4,  5,  6,  7],
         [ 8,  9, 10, 11],
         [12, 13, 14, 15],
         [16, 17, 18, 19],
         [20, 21, 22, 23]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zeros, ones, randn = torch.zeros(<span class="number">2</span>, <span class="number">3</span>), torch.ones(<span class="number">2</span>, <span class="number">3</span>), torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zeros, ones, randn</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[0., 0., 0.],
         [0., 0., 0.]]),
 tensor([[1., 1., 1.],
         [1., 1., 1.]]),
 tensor([[-0.7930,  0.2799,  0.7478],
         [-1.2043,  0.7893,  2.0885]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorX = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorX</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 2, 3],
        [4, 5, 6]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X, Y = torch.tensor([<span class="number">1.0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>]), torch.tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X + Y, X - Y, X * Y, X / Y, X ** Y</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([ 3.,  4.,  6., 10.]),
 tensor([-1.,  0.,  2.,  6.]),
 tensor([ 2.,  4.,  8., 16.]),
 tensor([0.5000, 1.0000, 2.0000, 4.0000]),
 tensor([ 1.,  4., 16., 64.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(X)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a, b =torch.arange(<span class="number">12</span>, dtype = torch.float64).reshape(<span class="number">3</span>, <span class="number">4</span>), torch.tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat((a, b), dim = <span class="number">0</span>), torch.cat((a, b), dim = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [ 2.,  1.,  4.,  3.],
         [ 1.,  2.,  3.,  4.],
         [ 4.,  3.,  2.,  1.]], dtype=torch.float64),
 tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]], dtype=torch.float64))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a == b</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[False,  True, False,  True],
        [False, False, False, False],
        [False, False, False, False]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.<span class="built_in">sum</span>(), b.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>(tensor(66., dtype=torch.float64), tensor(30.))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p, q = torch.arange(<span class="number">3</span>).reshape((<span class="number">3</span>, <span class="number">1</span>)), torch.arange(<span class="number">2</span>).reshape((<span class="number">1</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p, q</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[0],
         [1],
         [2]]),
 tensor([[0, 1]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">q + p</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0, 1],
        [1, 2],
        [2, 3]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr = torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">arr</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-0.2175,  1.2975, -1.4377, -0.6559],
        [-0.4125,  0.2430,  0.6188,  0.8181],
        [-0.7755,  0.2852,  0.8682,  0.5547]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[:]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-0.2175,  1.2975, -1.4377, -0.6559],
        [-0.4125,  0.2430,  0.6188,  0.8181],
        [-0.7755,  0.2852,  0.8682,  0.5547]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[<span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-0.4125,  0.2430,  0.6188,  0.8181],
        [-0.7755,  0.2852,  0.8682,  0.5547]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([-0.7755,  0.2852,  0.8682,  0.5547])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[<span class="number">1</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor(0.6188)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[<span class="number">1</span>, <span class="number">2</span>] = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[:]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-0.2175,  1.2975, -1.4377, -0.6559],
        [-0.4125,  0.2430,  0.0000,  0.8181],
        [-0.7755,  0.2852,  0.8682,  0.5547]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[<span class="number">0</span>:<span class="number">2</span>, :]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-0.2175,  1.2975, -1.4377, -0.6559],
        [-0.4125,  0.2430,  0.0000,  0.8181]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[<span class="number">0</span>:<span class="number">2</span>, :] = <span class="number">12.</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr[:]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[12.0000, 12.0000, 12.0000, 12.0000],
        [12.0000, 12.0000, 12.0000, 12.0000],
        [-0.7755,  0.2852,  0.8682,  0.5547]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">before = <span class="built_in">id</span>(arr)</span><br><span class="line">brr = torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr = arr + brr</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">id</span>(arr) == before</span><br></pre></td></tr></table></figure>




<pre><code>False
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Z = torch.zeros_like(arr)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(Z))</span><br></pre></td></tr></table></figure>

<pre><code>140595909928264
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Z[:] = arr + brr</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(Z))</span><br></pre></td></tr></table></figure>

<pre><code>140595909928264
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before = <span class="built_in">id</span>(arr)</span><br><span class="line">arr += brr</span><br><span class="line"><span class="built_in">id</span>(arr) == before</span><br></pre></td></tr></table></figure>




<pre><code>True
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = arr.numpy()</span><br><span class="line">B = torch.tensor(A)</span><br><span class="line"><span class="built_in">type</span>(A), <span class="built_in">type</span>(B)</span><br></pre></td></tr></table></figure>




<pre><code>(numpy.ndarray, torch.Tensor)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">3.5</span>])</span><br><span class="line">a, a.item(), <span class="built_in">float</span>(a), <span class="built_in">int</span>(a)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([3.5000]), 3.5, 3.5, 3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">4.0</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0., 1., 2., 3.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="number">2</span> * torch.dot(x, x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>




<pre><code>tensor(28., grad_fn=&lt;MulBackward0&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward()</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 0.,  4.,  8., 12.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.grad == <span class="number">4</span> * x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([True, True, True, True])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0., 0., 0., 0.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = x.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y.backward()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.grad</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1., 1., 1., 1.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x, y = torch.tensor([<span class="number">3.0</span>]), torch.tensor([<span class="number">2.0</span>])</span><br><span class="line">x + y, x - y, x * y, x / y, x ** y</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([5.]), tensor([1.]), tensor([6.]), tensor([1.5000]), tensor([9.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">4</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0, 1, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[<span class="number">3</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor(3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(x)</span><br></pre></td></tr></table></figure>




<pre><code>4
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(<span class="number">20</span>).reshape(<span class="number">5</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11],
        [12, 13, 14, 15],
        [16, 17, 18, 19]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.T</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  4,  8, 12, 16],
        [ 1,  5,  9, 13, 17],
        [ 2,  6, 10, 14, 18],
        [ 3,  7, 11, 15, 19]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">B = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">0</span>, <span class="number">4</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line">B, B.T</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[1, 2, 3],
         [2, 0, 4],
         [3, 4, 5]]),
 tensor([[1, 2, 3],
         [2, 0, 4],
         [3, 4, 5]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B == B.T</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[True, True, True],
        [True, True, True],
        [True, True, True]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[ 0,  1,  2,  3],
         [ 4,  5,  6,  7],
         [ 8,  9, 10, 11]],

        [[12, 13, 14, 15],
         [16, 17, 18, 19],
         [20, 21, 22, 23]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(<span class="number">20</span>, dtype = torch.float64).reshape(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">B = A.clone()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A, A + B</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [12., 13., 14., 15.],
         [16., 17., 18., 19.]], dtype=torch.float64),
 tensor([[ 0.,  2.,  4.,  6.],
         [ 8., 10., 12., 14.],
         [16., 18., 20., 22.],
         [24., 26., 28., 30.],
         [32., 34., 36., 38.]], dtype=torch.float64))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A * B <span class="comment">#对应乘积</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[  0.,   1.,   4.,   9.],
        [ 16.,  25.,  36.,  49.],
        [ 64.,  81., 100., 121.],
        [144., 169., 196., 225.],
        [256., 289., 324., 361.]], dtype=torch.float64)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">4</span>, dtype = torch.float64)</span><br><span class="line">x, x.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([0., 1., 2., 3.], dtype=torch.float64),
 tensor(6., dtype=torch.float64))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.shape, A.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>(torch.Size([5, 4]), tensor(190., dtype=torch.float64))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2023-01-11-torch-repeat/" data-id="cll50ezx3000dxpbi39lealef" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2023-01-10-wsl2-Ubuntu1804-install-CUDA-Pytorch" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2023-01-10-wsl2-Ubuntu1804-install-CUDA-Pytorch/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.712Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Init-Ubuntu-and-change-deb-pip-source"><a href="#Init-Ubuntu-and-change-deb-pip-source" class="headerlink" title="Init Ubuntu and change deb&amp;pip source"></a>Init Ubuntu and change deb&amp;pip source</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/ebxeax/ebxeax.github.io/blob/main/toolbox/initUbuntu/initUbuntu.sh</span><br><span class="line">bash ./initUbuntu.sh</span><br></pre></td></tr></table></figure>

<h2 id="CUDA11-6"><a href="#CUDA11-6" class="headerlink" title="CUDA11.6"></a>CUDA11.6</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin</span><br><span class="line">sudo <span class="built_in">mv</span> cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600</span><br><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.6.2/local_installers/cuda-repo-wsl-ubuntu-11-6-local_11.6.2-1_amd64.deb</span><br><span class="line">sudo dpkg -i cuda-repo-wsl-ubuntu-11-6-local_11.6.2-1_amd64.deb</span><br><span class="line">sudo apt-key add /var/cuda-repo-wsl-ubuntu-11-6-<span class="built_in">local</span>/7fa2af80.pub</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y install cuda</span><br></pre></td></tr></table></figure>
<h2 id="Load-library-path"><a href="#Load-library-path" class="headerlink" title="Load library path"></a>Load library path</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gedit ~/.bashrc</span><br><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64:<span class="variable">$LD_LIBRARY_PAT</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

<h2 id="Test-nvidia-smi"><a href="#Test-nvidia-smi" class="headerlink" title="Test nvidia-smi"></a>Test nvidia-smi</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<h2 id="Test-nvcc-V"><a href="#Test-nvcc-V" class="headerlink" title="Test nvcc -V"></a>Test nvcc -V</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure>

<h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113</span><br></pre></td></tr></table></figure>
<h3 id="get-file-when-network-worse"><a href="#get-file-when-network-worse" class="headerlink" title="get file when network worse"></a>get file when network worse</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://download.pytorch.org/whl/cu113/torch-1.10.2%2Bcu113-cp36-cp36m-linux_x86_64.whl</span><br><span class="line">wget https://download.pytorch.org/whl/cu113/torchvision-0.11.3%2Bcu113-cp36-cp36m-linux_x86_64.whl</span><br><span class="line">wget </span><br><span class="line">pip3 install ./torch-1.10.2+cu113-cp36-cp36m-linux_x86_64.whl</span><br><span class="line">pip3 install ./torchvision-0.11.3+cu113-cp36-cp36m-linux_x86_64.whl</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2023-01-10-wsl2-Ubuntu1804-install-CUDA-Pytorch/" data-id="cll50ezx1000cxpbi7yv75t1b" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-yolov1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-yolov1/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.665Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>当我们谈起计算机视觉时，首先想到的就是图像分类，没错，图像分类是计算机视觉最基本的任务之一，但是在图像分类的基础上，还有更复杂和有意思的任务，如目标检测，物体定位，图像分割等，见图1所示。其中目标检测是一件比较实际的且具有挑战性的计算机视觉任务，其可以看成图像分类与定位的结合，给定一张图片，目标检测系统要能够识别出图片的目标并给出其位置，由于图片中目标数是不定的，且要给出目标的精确位置，目标检测相比分类任务更复杂。目标检测的一个实际应用场景就是无人驾驶，如果能够在无人车上装载一个有效的目标检测系统，那么无人车将和人一样有了眼睛，可以快速地检测出前面的行人与车辆，从而作出实时决策。</p>
<p><img src="https://pic3.zhimg.com/80/v2-4a8db9d67ca78afe04d5610e31e6061a_720w.jpg" alt="img">图1 计算机视觉任务（来源: cs231n）</p>
<p>近几年来，目标检测算法取得了很大的突破。比较流行的算法可以分为两类，一类是基于Region Proposal的R-CNN系算法（R-CNN，Fast R-CNN, Faster R-CNN），它们是two-stage的，需要先使用启发式方法（selective search）或者CNN网络（RPN）产生Region Proposal，然后再在Region Proposal上做分类与回归。而另一类是Yolo，SSD这类one-stage算法，其仅仅使用一个CNN网络直接预测不同目标的类别与位置。第一类方法是准确度高一些，但是速度慢，但是第二类算法是速度快，但是准确性要低一些。这可以在图2中看到。本文介绍的是Yolo算法，其全称是You Only Look Once: Unified, Real-Time Object Detection，其实个人觉得这个题目取得非常好，基本上把Yolo算法的特点概括全了：You Only Look Once说的是只需要一次CNN运算，Unified指的是这是一个统一的框架，提供end-to-end的预测，而Real-Time体现是Yolo算法速度快。这里我们谈的是Yolo-v1版本算法，其性能是差于后来的SSD算法的，但是Yolo后来也继续进行改进，产生了Yolo9000算法。本文主要讲述Yolo-v1算法的原理，特别是算法的训练与预测中详细细节，最后将给出如何使用TensorFlow实现Yolo算法。</p>
<p><img src="https://pic3.zhimg.com/80/v2-497f2c3efd752f31601e26d0523f70c2_720w.jpg" alt="img">图2 目标检测算法进展与对比</p>
<h2 id="滑动窗口与CNN"><a href="#滑动窗口与CNN" class="headerlink" title="滑动窗口与CNN"></a>滑动窗口与CNN</h2><p>在介绍Yolo算法之前，首先先介绍一下滑动窗口技术，这对我们理解Yolo算法是有帮助的。采用滑动窗口的目标检测算法思路非常简单，它将检测问题转化为了图像分类问题。其基本原理就是采用不同大小和比例（宽高比）的窗口在整张图片上以一定的步长进行滑动，然后对这些窗口对应的区域做图像分类，这样就可以实现对整张图片的检测了，如下图3所示，如DPM就是采用这种思路。但是这个方法有致命的缺点，就是你并不知道要检测的目标大小是什么规模，所以你要设置不同大小和比例的窗口去滑动，而且还要选取合适的步长。但是这样会产生很多的子区域，并且都要经过分类器去做预测，这需要很大的计算量，所以你的分类器不能太复杂，因为要保证速度。解决思路之一就是减少要分类的子区域，这就是R-CNN的一个改进策略，其采用了selective search方法来找到最有可能包含目标的子区域（Region Proposal），其实可以看成采用启发式方法过滤掉很多子区域，这会提升效率。</p>
<p><img src="https://pic1.zhimg.com/80/v2-1a6f0fc27b69040b0c16ca480444edf8_720w.jpg" alt="img">图3 采用滑动窗口进行目标检测（来源：deeplearning.ai）</p>
<p>如果你使用的是CNN分类器，那么滑动窗口是非常耗时的。但是结合卷积运算的特点，我们可以使用CNN实现更高效的滑动窗口方法。这里要介绍的是一种全卷积的方法，简单来说就是网络中用卷积层代替了全连接层，如图4所示。输入图片大小是16x16，经过一系列卷积操作，提取了2x2的特征图，但是这个2x2的图上每个元素都是和原图是一一对应的，如图上蓝色的格子对应蓝色的区域，这不就是相当于在原图上做大小为14x14的窗口滑动，且步长为2，共产生4个字区域。最终输出的通道数为4，可以看成4个类别的预测概率值，这样一次CNN计算就可以实现窗口滑动的所有子区域的分类预测。这其实是overfeat算法的思路。之所可以CNN可以实现这样的效果是因为卷积操作的特性，就是图片的空间位置信息的不变性，尽管卷积过程中图片大小减少，但是位置对应关系还是保存的。说点题外话，这个思路也被R-CNN借鉴，从而诞生了Fast R-cNN算法。</p>
<p><img src="https://pic3.zhimg.com/80/v2-657d39aaeb56bf586cb18f733244c8e6_720w.jpg" alt="img">图4 滑动窗口的CNN实现（来源：deeplearning.ai）</p>
<p>上面尽管可以减少滑动窗口的计算量，但是只是针对一个固定大小与步长的窗口，这是远远不够的。Yolo算法很好的解决了这个问题，它不再是窗口滑动了，而是直接将原始图片分割成互不重合的小方块，然后通过卷积最后生产这样大小的特征图，基于上面的分析，可以认为特征图的每个元素也是对应原始图片的一个小方块，然后用每个元素来可以预测那些中心点在该小方格内的目标，这就是Yolo算法的朴素思想。下面将详细介绍Yolo算法的设计理念。</p>
<h2 id="设计理念"><a href="#设计理念" class="headerlink" title="设计理念"></a>设计理念</h2><p>整体来看，Yolo算法采用一个单独的CNN模型实现end-to-end的目标检测，整个系统如图5所示：首先将输入图片resize到448x448，然后送入CNN网络，最后处理网络预测结果得到检测的目标。相比R-CNN算法，其是一个统一的框架，其速度更快，而且Yolo的训练过程也是end-to-end的。</p>
<p><img src="https://pic4.zhimg.com/80/v2-d37bcff4e377a514aabfb0e371ccdf7b_720w.jpg" alt="img">图5 Yolo检测系统</p>
<p>具体来说，Yolo的CNN网络将输入的图片分割成 <img src="https://www.zhihu.com/equation?tex=S%5Ctimes+S" alt="[公式]"> 网格，然后每个单元格负责去检测那些中心点落在该格子内的目标，如图6所示，可以看到狗这个目标的中心落在左下角一个单元格内，那么该单元格负责预测这个狗。每个单元格会预测 <img src="https://www.zhihu.com/equation?tex=B" alt="[公式]"> 个边界框（bounding box）以及边界框的置信度（confidence score）。所谓置信度其实包含两个方面，一是这个边界框含有目标的可能性大小，二是这个边界框的准确度。前者记为 <img src="https://www.zhihu.com/equation?tex=Pr(object)" alt="[公式]"> ，当该边界框是背景时（即不包含目标），此时 <img src="https://www.zhihu.com/equation?tex=Pr(object)=0" alt="[公式]"> 。而当该边界框包含目标时， <img src="https://www.zhihu.com/equation?tex=Pr(object)=1" alt="[公式]"> 。边界框的准确度可以用预测框与实际框（ground truth）的IOU（intersection over union，交并比）来表征，记为 <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BIOU%7D%5E%7Btruth%7D_%7Bpred%7D" alt="[公式]"> 。因此置信度可以定义为 <img src="https://www.zhihu.com/equation?tex=Pr(object)*%5Ctext%7BIOU%7D%5E%7Btruth%7D_%7Bpred%7D" alt="[公式]"> 。很多人可能将Yolo的置信度看成边界框是否含有目标的概率，但是其实它是两个因子的乘积，预测框的准确度也反映在里面。边界框的大小与位置可以用4个值来表征： <img src="https://www.zhihu.com/equation?tex=(x,+y,w,h)" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=(x,y)" alt="[公式]"> 是边界框的中心坐标，而 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 是边界框的宽与高。还有一点要注意，中心坐标的预测值 <img src="https://www.zhihu.com/equation?tex=(x,y)" alt="[公式]"> 是相对于每个单元格左上角坐标点的偏移值，并且单位是相对于单元格大小的，单元格的坐标定义如图6所示。而边界框的 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 预测值是相对于整个图片的宽与高的比例，这样理论上4个元素的大小应该在 <img src="https://www.zhihu.com/equation?tex=%5B0,1%5D" alt="[公式]"> 范围。这样，每个边界框的预测值实际上包含5个元素： <img src="https://www.zhihu.com/equation?tex=(x,y,w,h,c)" alt="[公式]"> ，其中前4个表征边界框的大小与位置，而最后一个值是置信度。</p>
<p><img src="https://pic2.zhimg.com/80/v2-fdfea5fcb4ff3ecc327758878e4ad6e1_720w.jpg" alt="img">图6 网格划分</p>
<p>还有分类问题，对于每一个单元格其还要给出预测出 <img src="https://www.zhihu.com/equation?tex=C" alt="[公式]"> 个类别概率值，其表征的是由该单元格负责预测的边界框其目标属于各个类别的概率。但是这些概率值其实是在各个边界框置信度下的条件概率，即 <img src="https://www.zhihu.com/equation?tex=Pr(class_%7Bi%7D%7Cobject)" alt="[公式]"> 。值得注意的是，不管一个单元格预测多少个边界框，其只预测一组类别概率值，这是Yolo算法的一个缺点，在后来的改进版本中，Yolo9000是把类别概率预测值与边界框是绑定在一起的。同时，我们可以计算出各个边界框类别置信度（class-specific confidence scores）: <img src="https://www.zhihu.com/equation?tex=Pr(class_%7Bi%7D%7Cobject)*Pr(object)*%5Ctext%7BIOU%7D%5E%7Btruth%7D_%7Bpred%7D=Pr(class_%7Bi%7D)*%5Ctext%7BIOU%7D%5E%7Btruth%7D_%7Bpred%7D" alt="[公式]"> 。</p>
<p>边界框类别置信度表征的是该边界框中目标属于各个类别的可能性大小以及边界框匹配目标的好坏。后面会说，一般会根据类别置信度来过滤网络的预测框。</p>
<p>总结一下，每个单元格需要预测 <img src="https://www.zhihu.com/equation?tex=(B*5+C)" alt="[公式]"> 个值。如果将输入图片划分为 <img src="https://www.zhihu.com/equation?tex=S%5Ctimes+S" alt="[公式]"> 网格，那么最终预测值为 <img src="https://www.zhihu.com/equation?tex=S%5Ctimes+S%5Ctimes+(B*5+C)" alt="[公式]"> 大小的张量。整个模型的预测值结构如下图所示。对于PASCAL VOC数据，其共有20个类别，如果使用 <img src="https://www.zhihu.com/equation?tex=S=7,B=2" alt="[公式]"> ，那么最终的预测结果就是 <img src="https://www.zhihu.com/equation?tex=7%5Ctimes+7%5Ctimes+30" alt="[公式]"> 大小的张量。在下面的网络结构中我们会详细讲述每个单元格的预测值的分布位置。</p>
<p><img src="https://pic3.zhimg.com/80/v2-258df167ee37b5594c72562b4ae61d1a_720w.jpg" alt="img">图7 模型预测值结构</p>
<h2 id="网络设计"><a href="#网络设计" class="headerlink" title="网络设计"></a>网络设计</h2><p>Yolo采用卷积网络来提取特征，然后使用全连接层来得到预测值。网络结构参考GooLeNet模型，包含24个卷积层和2个全连接层，如图8所示。对于卷积层，主要使用1x1卷积来做channle reduction，然后紧跟3x3卷积。对于卷积层和全连接层，采用Leaky ReLU激活函数： <img src="https://www.zhihu.com/equation?tex=max(x,+0.1x)" alt="[公式]"> 。但是最后一层却采用线性激活函数。</p>
<p><img src="https://pic4.zhimg.com/80/v2-5d099287b1237fa975b1c19bacdfc07f_720w.jpg" alt="img">图8 网络结构</p>
<p>可以看到网络的最后输出为 <img src="https://www.zhihu.com/equation?tex=7%5Ctimes+7%5Ctimes+30" alt="[公式]"> 大小的张量。这和前面的讨论是一致的。这个张量所代表的具体含义如图9所示。对于每一个单元格，前20个元素是类别概率值，然后2个元素是边界框置信度，两者相乘可以得到类别置信度，最后8个元素是边界框的 <img src="https://www.zhihu.com/equation?tex=(x,+y,w,h)" alt="[公式]"> 。大家可能会感到奇怪，对于边界框为什么把置信度 <img src="https://www.zhihu.com/equation?tex=c" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=(x,+y,w,h)" alt="[公式]"> 都分开排列，而不是按照 <img src="https://www.zhihu.com/equation?tex=(x,+y,w,h,c)" alt="[公式]"> 这样排列，其实纯粹是为了计算方便，因为实际上这30个元素都是对应一个单元格，其排列是可以任意的。但是分离排布，可以方便地提取每一个部分。这里来解释一下，首先网络的预测值是一个二维张量 <img src="https://www.zhihu.com/equation?tex=P" alt="[公式]"> ，其shape为 <img src="https://www.zhihu.com/equation?tex=%5Bbatch,+7%5Ctimes+7%5Ctimes+30%5D" alt="[公式]"> 。采用切片，那么 <img src="https://www.zhihu.com/equation?tex=P_%7B%5B:,0:7*7*20%5D%7D" alt="[公式]"> 就是类别概率部分，而 <img src="https://www.zhihu.com/equation?tex=P_%7B%5B:,7*7*20:7*7*(20+2)%5D%7D" alt="[公式]"> 是置信度部分，最后剩余部分 <img src="https://www.zhihu.com/equation?tex=P_%7B%5B:,7*7*(20+2):%5D%7D" alt="[公式]"> 是边界框的预测结果。这样，提取每个部分是非常方便的，这会方面后面的训练及预测时的计算。</p>
<p><img src="https://pic1.zhimg.com/80/v2-8630f8d3dbe3634f124eaf82f222ca94_720w.jpg" alt="img">图9 预测张量的解析</p>
<h2 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h2><p>在训练之前，先在ImageNet上进行了预训练，其预训练的分类模型采用图8中前20个卷积层，然后添加一个average-pool层和全连接层。预训练之后，在预训练得到的20层卷积层之上加上随机初始化的4个卷积层和2个全连接层。由于检测任务一般需要更高清的图片，所以将网络的输入从224x224增加到了448x448。整个网络的流程如下图所示：</p>
<p><img src="https://pic4.zhimg.com/80/v2-40c8cbed60aba0fe2faa38e240b8563b_720w.jpg" alt="img">图10 Yolo网络流程</p>
<p>下面是训练损失函数的分析，Yolo算法将目标检测看成回归问题，所以采用的是均方差损失函数。但是对不同的部分采用了不同的权重值。首先区分定位误差和分类误差。对于定位误差，即边界框坐标预测误差，采用较大的权重 <img src="https://www.zhihu.com/equation?tex=%5Clambda+_%7Bcoord%7D=5" alt="[公式]"> 。然后其区分不包含目标的边界框与含有目标的边界框的置信度，对于前者，采用较小的权重值 <img src="https://www.zhihu.com/equation?tex=%5Clambda+_%7Bnoobj%7D=0.5" alt="[公式]"> 。其它权重值均设为1。然后采用均方误差，其同等对待大小不同的边界框，但是实际上较小的边界框的坐标误差应该要比较大的边界框要更敏感。为了保证这一点，将网络的边界框的宽与高预测改为对其平方根的预测，即预测值变为 <img src="https://www.zhihu.com/equation?tex=(x,y,%5Csqrt%7Bw%7D,+%5Csqrt%7Bh%7D)" alt="[公式]"> 。</p>
<p>另外一点时，由于每个单元格预测多个边界框。但是其对应类别只有一个。那么在训练时，如果该单元格内确实存在目标，那么只选择与ground truth的IOU最大的那个边界框来负责预测该目标，而其它边界框认为不存在目标。这样设置的一个结果将会使一个单元格对应的边界框更加专业化，其可以分别适用不同大小，不同高宽比的目标，从而提升模型性能。大家可能会想如果一个单元格内存在多个目标怎么办，其实这时候Yolo算法就只能选择其中一个来训练，这也是Yolo算法的缺点之一。要注意的一点时，对于不存在对应目标的边界框，其误差项就是只有置信度，坐标项误差是没法计算的。而只有当一个单元格内确实存在目标时，才计算分类误差项，否则该项也是无法计算的。</p>
<p>综上讨论，最终的损失函数计算如下：</p>
<p><img src="https://pic3.zhimg.com/80/v2-45795a63cdbaac8c05d875dfb6fcfb5a_720w.jpg" alt="img"></p>
<p>其中第一项是边界框中心坐标的误差项， <img src="https://www.zhihu.com/equation?tex=1%5E%7Bobj%7D_%7Bij%7D" alt="[公式]"> 指的是第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 个单元格存在目标，且该单元格中的第 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 个边界框负责预测该目标。第二项是边界框的高与宽的误差项。第三项是包含目标的边界框的置信度误差项。第四项是不包含目标的边界框的置信度误差项。而最后一项是包含目标的单元格的分类误差项， <img src="https://www.zhihu.com/equation?tex=1%5E%7Bobj%7D_%7Bi%7D" alt="[公式]"> 指的是第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 个单元格存在目标。这里特别说一下置信度的target值 <img src="https://www.zhihu.com/equation?tex=C_i" alt="[公式]"> ，如果是不存在目标，此时由于 <img src="https://www.zhihu.com/equation?tex=Pr(object)=0" alt="[公式]">，那么 <img src="https://www.zhihu.com/equation?tex=C_i=0" alt="[公式]"> 。如果存在目标， <img src="https://www.zhihu.com/equation?tex=Pr(object)=1" alt="[公式]"> ，此时需要确定 <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BIOU%7D%5E%7Btruth%7D_%7Bpred%7D" alt="[公式]"> ，当然你希望最好的话，可以将IOU取1，这样 <img src="https://www.zhihu.com/equation?tex=C_i=1" alt="[公式]"> ，但是在YOLO实现中，使用了一个控制参数rescore（默认为1），当其为1时，IOU不是设置为1，而就是计算truth和pred之间的真实IOU。不过很多复现YOLO的项目还是取 <img src="https://www.zhihu.com/equation?tex=C_i=1" alt="[公式]"> ，这个差异应该不会太影响结果吧。</p>
<h2 id="网络预测"><a href="#网络预测" class="headerlink" title="网络预测"></a>网络预测</h2><p>在说明Yolo算法的预测过程之前，这里先介绍一下非极大值抑制算法（non maximum suppression, NMS），这个算法不单单是针对Yolo算法的，而是所有的检测算法中都会用到。NMS算法主要解决的是一个目标被多次检测的问题，如图11中人脸检测，可以看到人脸被多次检测，但是其实我们希望最后仅仅输出其中一个最好的预测框，比如对于美女，只想要红色那个检测结果。那么可以采用NMS算法来实现这样的效果：首先从所有的检测框中找到置信度最大的那个框，然后挨个计算其与剩余框的IOU，如果其值大于一定阈值（重合度过高），那么就将该框剔除；然后对剩余的检测框重复上述过程，直到处理完所有的检测框。Yolo预测过程也需要用到NMS算法。</p>
<p><img src="https://pic3.zhimg.com/80/v2-21f14aaa1cd64ab69fc7389044e1bd3a_720w.jpg" alt="img">图11 NMS应用在人脸检测</p>
<p>下面就来分析Yolo的预测过程，这里我们不考虑batch，认为只是预测一张输入图片。根据前面的分析，最终的网络输出是 <img src="https://www.zhihu.com/equation?tex=7%5Ctimes+7+%5Ctimes+30" alt="[公式]"> ，但是我们可以将其分割成三个部分：类别概率部分为 <img src="https://www.zhihu.com/equation?tex=%5B7,+7,+20%5D" alt="[公式]"> ，置信度部分为 <img src="https://www.zhihu.com/equation?tex=%5B7,7,2%5D" alt="[公式]"> ，而边界框部分为 <img src="https://www.zhihu.com/equation?tex=%5B7,7,2,4%5D" alt="[公式]"> （对于这部分不要忘记根据原始图片计算出其真实值）。然后将前两项相乘（矩阵 <img src="https://www.zhihu.com/equation?tex=%5B7,+7,+20%5D" alt="[公式]"> 乘以 <img src="https://www.zhihu.com/equation?tex=%5B7,7,2%5D" alt="[公式]"> 可以各补一个维度来完成 <img src="https://www.zhihu.com/equation?tex=%5B7,7,1,20%5D%5Ctimes+%5B7,7,2,1%5D" alt="[公式]"> ）可以得到类别置信度值为 <img src="https://www.zhihu.com/equation?tex=%5B7,+7,2,20%5D" alt="[公式]"> ，这里总共预测了 <img src="https://www.zhihu.com/equation?tex=7*7*2=98" alt="[公式]"> 个边界框。</p>
<p>所有的准备数据已经得到了，那么我们先说第一种策略来得到检测框的结果，我认为这是最正常与自然的处理。首先，对于每个预测框根据类别置信度选取置信度最大的那个类别作为其预测标签，经过这层处理我们得到各个预测框的预测类别及对应的置信度值，其大小都是 <img src="https://www.zhihu.com/equation?tex=%5B7,7,2%5D" alt="[公式]"> 。一般情况下，会设置置信度阈值，就是将置信度小于该阈值的box过滤掉，所以经过这层处理，剩余的是置信度比较高的预测框。最后再对这些预测框使用NMS算法，最后留下来的就是检测结果。一个值得注意的点是NMS是对所有预测框一视同仁，还是区分每个类别，分别使用NMS。Ng在deeplearning.ai中讲应该区分每个类别分别使用NMS，但是看了很多实现，其实还是同等对待所有的框，我觉得可能是不同类别的目标出现在相同位置这种概率很低吧。</p>
<p>上面的预测方法应该非常简单明了，但是对于Yolo算法，其却采用了另外一个不同的处理思路（至少从C源码看是这样的），其区别就是先使用NMS，然后再确定各个box的类别。其基本过程如图12所示。对于98个boxes，首先将小于置信度阈值的值归0，然后分类别地对置信度值采用NMS，这里NMS处理结果不是剔除，而是将其置信度值归为0。最后才是确定各个box的类别，当其置信度值不为0时才做出检测结果输出。这个策略不是很直接，但是貌似Yolo源码就是这样做的。Yolo论文里面说NMS算法对Yolo的性能是影响很大的，所以可能这种策略对Yolo更好。但是我测试了普通的图片检测，两种策略结果是一样的。</p>
<p><img src="https://pic3.zhimg.com/80/v2-47651d0a677009d58c899c215d342e06_720w.jpg" alt="img">图12 Yolo的预测处理流程</p>
<h2 id="算法性能分析"><a href="#算法性能分析" class="headerlink" title="算法性能分析"></a>算法性能分析</h2><p>这里看一下Yolo算法在PASCAL VOC 2007数据集上的性能，这里Yolo与其它检测算法做了对比，包括DPM，R-CNN，Fast R-CNN以及Faster R-CNN。其对比结果如表1所示。与实时性检测方法DPM对比，可以看到Yolo算法可以在较高的mAP上达到较快的检测速度，其中Fast Yolo算法比快速DPM还快，而且mAP是远高于DPM。但是相比Faster R-CNN，Yolo的mAP稍低，但是速度更快。所以。Yolo算法算是在速度与准确度上做了折中。</p>
<p><img src="https://pic4.zhimg.com/80/v2-3da4029640307f737719843b389fc0ff_720w.jpg" alt="img">表1 Yolo在PASCAL VOC 2007上与其他算法的对比</p>
<p>为了进一步分析Yolo算法，文章还做了误差分析，将预测结果按照分类与定位准确性分成以下5类：</p>
<ul>
<li>Correct：类别正确，IOU&gt;0.5；（准确度）</li>
<li>Localization：类别正确，0.1 &lt; IOU&lt;0.5（定位不准）；</li>
<li>Similar：类别相似，IOU&gt;0.1；</li>
<li>Other：类别错误，IOU&gt;0.1；</li>
<li>Background：对任何目标其IOU&lt;0.1。（误把背景当物体）</li>
</ul>
<p>Yolo与Fast R-CNN的误差对比分析如下图所示：</p>
<p><img src="https://pic4.zhimg.com/80/v2-cb8bb72fad701466328b386da6a93943_720w.jpg" alt="img">图13 Yolo与Fast R-CNN的误差对比分析</p>
<p>可以看到，Yolo的Correct的是低于Fast R-CNN。另外Yolo的Localization误差偏高，即定位不是很准确。但是Yolo的Background误差很低，说明其对背景的误判率较低。Yolo的那篇文章中还有更多性能对比，感兴趣可以看看。</p>
<p>现在来总结一下Yolo的优缺点。首先是优点，Yolo采用一个CNN网络来实现检测，是单管道策略，其训练与预测都是end-to-end，所以Yolo算法比较简洁且速度快。第二点由于Yolo是对整张图片做卷积，所以其在检测目标有更大的视野，它不容易对背景误判。其实我觉得全连接层也是对这个有贡献的，因为全连接起到了attention的作用。另外，Yolo的泛化能力强，在做迁移时，模型鲁棒性高。</p>
<p>最后不得不谈一下Yolo的缺点，首先Yolo各个单元格仅仅预测两个边界框，而且属于一个类别。对于小物体，Yolo的表现会不如人意。这方面的改进可以看SSD，其采用多尺度单元格。也可以看Faster R-CNN，其采用了anchor boxes。Yolo对于在物体的宽高比方面泛化率低，就是无法定位不寻常比例的物体。当然Yolo的定位不准确也是很大的问题。</p>
<h2 id="算法的TF实现"><a href="#算法的TF实现" class="headerlink" title="算法的TF实现"></a>算法的TF实现</h2><p>Yolo的源码是用C实现的，但是好在Github上有很多开源的TF复现。这里我们参考gliese581gg的<a href="https://link.zhihu.com/?target=https://github.com/gliese581gg/YOLO_tensorflow">YOLO_tensorflow</a>的实现来分析Yolo的Inference实现细节。我们的代码将构建一个end-to-end的Yolo的预测模型，利用的已经训练好的权重文件，你将可以用自然的图片去测试检测效果。</p>
<p>首先，我们定义Yolo的模型参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Yolo</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weights_file, verbose=<span class="literal">True</span></span>):</span><br><span class="line">        self.verbose = verbose</span><br><span class="line">        <span class="comment"># detection params</span></span><br><span class="line">        self.S = <span class="number">7</span>  <span class="comment"># cell size</span></span><br><span class="line">        self.B = <span class="number">2</span>  <span class="comment"># boxes_per_cell</span></span><br><span class="line">        self.classes = [<span class="string">&quot;aeroplane&quot;</span>, <span class="string">&quot;bicycle&quot;</span>, <span class="string">&quot;bird&quot;</span>, <span class="string">&quot;boat&quot;</span>, <span class="string">&quot;bottle&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;bus&quot;</span>, <span class="string">&quot;car&quot;</span>, <span class="string">&quot;cat&quot;</span>, <span class="string">&quot;chair&quot;</span>, <span class="string">&quot;cow&quot;</span>, <span class="string">&quot;diningtable&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;dog&quot;</span>, <span class="string">&quot;horse&quot;</span>, <span class="string">&quot;motorbike&quot;</span>, <span class="string">&quot;person&quot;</span>, <span class="string">&quot;pottedplant&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;sheep&quot;</span>, <span class="string">&quot;sofa&quot;</span>, <span class="string">&quot;train&quot;</span>,<span class="string">&quot;tvmonitor&quot;</span>]</span><br><span class="line">        self.C = <span class="built_in">len</span>(self.classes) <span class="comment"># number of classes</span></span><br><span class="line">        <span class="comment"># offset for box center (top left point of each cell)</span></span><br><span class="line">        self.x_offset = np.transpose(np.reshape(np.array([np.arange(self.S)]*self.S*self.B),</span><br><span class="line">                                              [self.B, self.S, self.S]), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">        self.y_offset = np.transpose(self.x_offset, [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        self.threshold = <span class="number">0.2</span>  <span class="comment"># confidence scores threhold</span></span><br><span class="line">        self.iou_threshold = <span class="number">0.4</span></span><br><span class="line">        <span class="comment">#  the maximum number of boxes to be selected by non max suppression</span></span><br><span class="line">        self.max_output_size = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        self._build_net()</span><br><span class="line">        self._build_detector()</span><br><span class="line">        self._load_weights(weights_file)</span><br></pre></td></tr></table></figure>

<p>然后是我们模型的主体网络部分，这个网络将输出[batch,7<em>7</em>30]的张量:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_build_net</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;build the network&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Start to build the network ...&quot;</span>)</span><br><span class="line">        self.images = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">448</span>, <span class="number">448</span>, <span class="number">3</span>])</span><br><span class="line">        net = self._conv_layer(self.images, <span class="number">1</span>, <span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>)</span><br><span class="line">        net = self._maxpool_layer(net, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">2</span>, <span class="number">192</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._maxpool_layer(net, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">3</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">4</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">5</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">6</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._maxpool_layer(net, <span class="number">6</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">7</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">8</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">9</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">10</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">11</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">12</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">13</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">14</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">15</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">16</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._maxpool_layer(net, <span class="number">16</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">17</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">18</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">19</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">20</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">21</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">22</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">23</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._conv_layer(net, <span class="number">24</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        net = self._flatten(net)</span><br><span class="line">        net = self._fc_layer(net, <span class="number">25</span>, <span class="number">512</span>, activation=leak_relu)</span><br><span class="line">        net = self._fc_layer(net, <span class="number">26</span>, <span class="number">4096</span>, activation=leak_relu)</span><br><span class="line">        net = self._fc_layer(net, <span class="number">27</span>, self.S*self.S*(self.C+<span class="number">5</span>*self.B))</span><br><span class="line">        self.predicts = net</span><br></pre></td></tr></table></figure>

<p>接下来，我们要去解析网络的预测结果，这里采用了第一种预测策略，即判断预测框类别，再NMS，多亏了TF提供了NMS的函数<a href="https://link.zhihu.com/?target=https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression">tf.image.non_max_suppression</a>，其实实现起来很简单，所有的细节前面已经交代了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_build_detector</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Interpret the net output and get the predicted boxes&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># the width and height of orignal image</span></span><br><span class="line">        self.width = tf.placeholder(tf.float32, name=<span class="string">&quot;img_w&quot;</span>)</span><br><span class="line">        self.height = tf.placeholder(tf.float32, name=<span class="string">&quot;img_h&quot;</span>)</span><br><span class="line">        <span class="comment"># get class prob, confidence, boxes from net output</span></span><br><span class="line">        idx1 = self.S * self.S * self.C</span><br><span class="line">        idx2 = idx1 + self.S * self.S * self.B</span><br><span class="line">        <span class="comment"># class prediction</span></span><br><span class="line">        class_probs = tf.reshape(self.predicts[<span class="number">0</span>, :idx1], [self.S, self.S, self.C])</span><br><span class="line">        <span class="comment"># confidence</span></span><br><span class="line">        confs = tf.reshape(self.predicts[<span class="number">0</span>, idx1:idx2], [self.S, self.S, self.B])</span><br><span class="line">        <span class="comment"># boxes -&gt; (x, y, w, h)</span></span><br><span class="line">        boxes = tf.reshape(self.predicts[<span class="number">0</span>, idx2:], [self.S, self.S, self.B, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># convert the x, y to the coordinates relative to the top left point of the image</span></span><br><span class="line">        <span class="comment"># the predictions of w, h are the square root</span></span><br><span class="line">        <span class="comment"># multiply the width and height of image</span></span><br><span class="line">        boxes = tf.stack([(boxes[:, :, :, <span class="number">0</span>] + tf.constant(self.x_offset, dtype=tf.float32)) / self.S * self.width,</span><br><span class="line">                          (boxes[:, :, :, <span class="number">1</span>] + tf.constant(self.y_offset, dtype=tf.float32)) / self.S * self.height,</span><br><span class="line">                          tf.square(boxes[:, :, :, <span class="number">2</span>]) * self.width,</span><br><span class="line">                          tf.square(boxes[:, :, :, <span class="number">3</span>]) * self.height], axis=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># class-specific confidence scores [S, S, B, C]</span></span><br><span class="line">        scores = tf.expand_dims(confs, -<span class="number">1</span>) * tf.expand_dims(class_probs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        scores = tf.reshape(scores, [-<span class="number">1</span>, self.C])  <span class="comment"># [S*S*B, C]</span></span><br><span class="line">        boxes = tf.reshape(boxes, [-<span class="number">1</span>, <span class="number">4</span>])  <span class="comment"># [S*S*B, 4]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># find each box class, only select the max score</span></span><br><span class="line">        box_classes = tf.argmax(scores, axis=<span class="number">1</span>)</span><br><span class="line">        box_class_scores = tf.reduce_max(scores, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># filter the boxes by the score threshold</span></span><br><span class="line">        filter_mask = box_class_scores &gt;= self.threshold</span><br><span class="line">        scores = tf.boolean_mask(box_class_scores, filter_mask)</span><br><span class="line">        boxes = tf.boolean_mask(boxes, filter_mask)</span><br><span class="line">        box_classes = tf.boolean_mask(box_classes, filter_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># non max suppression (do not distinguish different classes)</span></span><br><span class="line">        <span class="comment"># ref: https://tensorflow.google.cn/api_docs/python/tf/image/non_max_suppression</span></span><br><span class="line">        <span class="comment"># box (x, y, w, h) -&gt; box (x1, y1, x2, y2)</span></span><br><span class="line">        _boxes = tf.stack([boxes[:, <span class="number">0</span>] - <span class="number">0.5</span> * boxes[:, <span class="number">2</span>], boxes[:, <span class="number">1</span>] - <span class="number">0.5</span> * boxes[:, <span class="number">3</span>],</span><br><span class="line">                           boxes[:, <span class="number">0</span>] + <span class="number">0.5</span> * boxes[:, <span class="number">2</span>], boxes[:, <span class="number">1</span>] + <span class="number">0.5</span> * boxes[:, <span class="number">3</span>]], axis=<span class="number">1</span>)</span><br><span class="line">        nms_indices = tf.image.non_max_suppression(_boxes, scores,</span><br><span class="line">                                                   self.max_output_size, self.iou_threshold)</span><br><span class="line">        self.scores = tf.gather(scores, nms_indices)</span><br><span class="line">        self.boxes = tf.gather(boxes, nms_indices)</span><br><span class="line">        self.box_classes = tf.gather(box_classes, nms_indices)</span><br></pre></td></tr></table></figure>

<p>其他的就比较容易了，详细代码附在<a href="https://link.zhihu.com/?target=https://github.com/xiaohu2015/DeepLearning_tutorials/blob/master/ObjectDetections/yolo/yolo_tf.py">xiaohu2015&#x2F;DeepLearning_tutorials</a>上了，欢迎给点个赞，权重文件在<a href="https://link.zhihu.com/?target=https://pan.baidu.com/s/1mhE0WL6">这里下载</a>。</p>
<p>最后就是愉快地测试你自己的图片了：</p>
<p><img src="https://pic2.zhimg.com/80/v2-cade4c6a5fef395d21cc2a663b403b15_720w.jpg" alt="img"></p>
<p>当然，如果你对训练过程感兴趣，你可以参考这里的实现<a href="https://link.zhihu.com/?target=https://github.com/thtrieu/darkflow">thtrieu&#x2F;darkflow</a>，如果你看懂了预测过程的代码，这里也会很容易阅读。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇长文详细介绍了Yolo算法的原理及实现，当然Yolo-v1还是有很多问题的，所以后续可以读读Yolo9000算法，看看其如何改进的。Ng说Yolo的paper是比较难读的，其实是很多实现细节，如果不看代码是很难理解的。所以，文章中如果有错误也可能是难免的，欢迎交流指正。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection</a>.</li>
<li><a href="https://link.zhihu.com/?target=https://pjreddie.com/darknet/yolo/">Yolo官网</a>.</li>
<li><a href="https://link.zhihu.com/?target=https://github.com/gliese581gg/YOLO_tensorflow">Yolo的TF实现</a>.</li>
<li><a href="https://link.zhihu.com/?target=https://www.youtube.com/watch?v=L0tzmv--CGY">YOLO: You only look once (How it works)</a>.（注：很多实现细节，需要墙）</li>
<li>Ng的<a href="https://link.zhihu.com/?target=https://www.deeplearning.ai/">deeplearning.ai</a>课程.</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-yolov1/" data-id="cll50ezwy000bxpbi73txbf8d" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-trafficReg" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-trafficReg/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.621Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD<br>原文链接：<a target="_blank" rel="noopener" href="https://medium.com/geoai/an-end-to-end-solution-on-the-cloud-to-monitor-traffic-flow-using-deep-learning-9dfdfd00b621">https://medium.com/geoai/an-end-to-end-solution-on-the-cloud-to-monitor-traffic-flow-using-deep-learning-9dfdfd00b621</a></p>
<p>本文将大致介绍如何结合监控视频流，ArcGIS，ArcGIS API for API，AWS等技术来监测车流量。</p>
<p>目录：</p>
<p>交通治理以及研究问题描述<br>实时视频流以及数据标注<br>目标检测：在AWS上训练YOLO3模型<br>流程架构<br>使用Dashboard应用实时监测路况<br>基于历史数据的异常行为监测<br>结论以及展望<br>致谢以及参考文献<br>交通治理以及问题研究描述<br>车流量是监测城市环境状态的一个重要要素。控制道路上车流量是一个非常基本的需求。在一些大城市，通常使用监控相机监测繁忙的道路，高速公路，以及十字路口。交通局工作人员通常对事故，路面覆盖物（雨，冰，雪），路面犯罪，抛锚，超速，拥堵，行人数量等信息感兴趣。监控相机可以帮助更好治理路况维持公共安全。国家高速公路安全管理局的一项研究表明，36%的碰撞事故都发生在道路交汇处。因此，十字路口时城市交通拥堵的罪魁祸首，也是交管中心重点监测对象。为了监测和管理路况，交通十字路口通常安装了许多相机。监测相机可以时固定，也可以是可遥控的PTZ相机。</p>
<p>监控抓拍图-昼</p>
<p>监控抓拍图-夜<br>于是，华盛顿区域的交通部门需要Esri定制一个云解决方案，方案需要满足以下需求：1）监测110个交通路口的路况（小汽车，公交，卡车，摩托车，行人），并且使用GIS将其可视化。2）监测路口流量异常。3）监测处在危险区域的行人。这个解决方案不仅需要监控相机，还需要将空间数据和深度学习框架结合。</p>
<p>本文将介绍，如何使用ArcGIS，ArcGIS API for Pyhon，AWS以及Keras深度学习框架实现这个解决方案。解决方案是使用AWS环境中的GPU来加速实时处理视频流，从而进行模型训练和推断预测。ArcGIS API for Python将空间信息如视频流的位置与深度学习框架结合，并且使用ArcGIS Enterprise将时间信息一同保存。</p>
<p>实时视频流以及数据标注<br>深度学习模型需要大量的训练数据。作者通过Traffic Land的REST API服务获取华盛顿111个路口的实视监控视频。作者使用Python代码，从TrafficLand服务上面获取了这111个监控相机的1000多张日夜抓拍图。作者将这些训练数据图片放到一个文件夹里面，然后使用LabelImg的工具人工标注图片中的目标物。最后将标注信息导出为txt文件，txt文件可以被绝大多数的目标检测算法使用。</p>
<p>使用LabelImg软件标注<br>目标检测：在AWS上训练YOLO3模型<br>我们的目的是从实时的视频中识别目标物。YOLO是一个目标检测很火的算法，该算法在实时应用中的精准度十分的高。YOLO可以生成目标物在图片中的位置，并且告诉用户该目标物的类别。YOLO只需要在网络中进行一次前向衍生就能够提供预测。早些版本的YOLO如YOLO2无法识别细小的目标物，因为YOLO2的计算层降低了输入图片的分辨率。除此之外，YOLO2还缺少一些牛叉的技术，如residual blocks，skip connections 以及 upsampling。YOLO3增加计算层以及YOLO2中那些没有的牛叉的功能。YOLO3算法在模型里面3个不同的位置，对尺寸不同的要素图运用1*1的识别窗口来实现目标检测。关于YOLO的原理有很多的博客和资源，这里不不做赘述。你可以在这些参考文献里了解YOLO的原理。</p>
<p>YOLO模型<br>来自111个监控相机的1000多张带有标签的日夜抓拍图将被用作训练数据，在AWS上面训练YOLO3模型。笔者使用了AWS的EC2实例，EC2实例提供专门用来深度学习的镜像，这些镜像通常预装自带了Tensorflow，PyTorch，Keras等框架，可以用于训练复杂的深度学习模型。笔者使用了预训练的YOLO3模型以及转移学习技术。随后作者对比了预测结果和实际结果。训练模型的IOU达95%。笔者使用了现成的开源Github代码训练YOLO3 模型。</p>
<p>流程架构<br>为了在AWS上面搭建一个实时流程，我们使用了如下架构来实现路况监测：1）我们使用并行处理来加速从TrafficLand REST API取视频流程的过程。2）紧接着，抓拍图被传到AWS EC2实例上的YOLO3模型里面。YOLO3对每一个片中的目标识别并且分类。总体上使用一个NVIDIA Tesla K80 GPU，我们可以在10内完成111张图片的抓取以及预测。3）最后我们将YOLO3的预测结果传到AWS的GeoEvent中的大数据库中，从而可以在大屏幕上对每一类数据进行可视化。每一个监控相机的相关照片都保存在S3 bucket云存储中。</p>
<p>流程架构设计图<br>我们的IT团队在AWS配置好了深度学习EC2实例以及ArcGIS GeoEvent Server。GeoEvent Server将实时的流数据与带有位置数据的要素类或大数据库相结合。为了将GeoEvent Server和EC2实例上的YOLO3深度学习模型相连接，笔者在GeoEvent服务中配置了输入连接器，处理器，输出连接器。GeoEvent服务可以通过用户图形界面创建，类似Model Builder的创建方法。</p>
<p>GeoEvent输入连接器定义了来自YOLO3模型的事件数据结构，并且把事件数据传送给GeoEvent处理器。如果你的数据结构有差异，GeoEvent将无法读取事件数据。GeoEvent中有好几种常用格式（文本，RSS，ESRI要素JSON，JSON）和协议（系统文件，HTTP，TCP，UDP，WebSocket，ESRI要素服务）的输入连接器。建立输入连接器是，用户要新建一个GeoEvent Definition，GeoEvent Definition里面定义了事件数据的数据结构。下图分别展示了GeoJSON格式的GeoEvent Definition，和RestAPI的数据通信渠道。因此，每一个相机的YOLO3模型的输出结果都会使用相机位置信息转换成GeoJSON。</p>
<p>GeoEvent Definition</p>
<p>GeoEvent Input Connector<br>GeoEvent处理器是GeoEvent服务里面的一个可配置元素。GeoEvent服务提供基于事件数据的分析，比如对事件数据进行识别，对事件数据进行扩充。由于我们的流程没有对事件数据做任何处理，因此我们的流程中将不会使用任何GeoEvent处理器。</p>
<p>GeoEvent输出连接器的作用是将GeoEvent数据重新转成符合各种协议的流数据。我们配置了两个GeoEvent服务：1）一个实时GeoEvent服务，用于获取实时数据以及大屏可视化。2）一个历史GeoEvent服务，用于保存历史数据要素类可以后续用于异常分析。这两个服务的不同之处在于，实时服务只保存最新的111条记录，然而历史服务会保存之前所有生成的记录。我们可以算一下按每秒111条记录的速率，一天数据量将达到9.6百万（111相机<em>24小时</em>60分*60秒）。</p>
<p>Update a Feature Ouput Connector</p>
<p>Add a Feature Output Connector<br>使用Dashboard应用实时监测路况<br>我们使用了Dashboard应用来实现自动化监测实时交通路况。Dashboard应用展示了111个实时视频流的位置，以及每个路口各种车型的计数。Dashboard的数据来自GeoEvent服务生成的要素类。用户通过Dashboard可以判断华盛顿区域行人或者车辆拥堵的具体位置。用户要可以看到每个监控相机的实时画面。下图展示了Dashboard应用的界面。Dashboard根据用户当前浏览的地图区域更新左侧的统计数据。</p>
<p>Dashboard应用</p>
<p>查询某一个路口<br>基于历史数据的异常行为监测<br>交通部门还想知道每一种车型和行人在路口的动态流量是如何的。为了解决这个问题，我们在一个礼拜后使用历史GeoEvent服务生成的数据来计算每一种车型和行人每天每一分钟的流量状况。我们简单计算一下，会有约1百万种可能的组合（111相机<em>7天</em>24小时*60分钟）。你可以把它比作一个异常监测的查询表。我们将每一种车型的计数与历史技术做比较，如果计数高于历史计数30%，那么我们称为流量异常，并且将异常展现在地图上。我们将异常事件写进一个单独的要素类里面。下图展示了某个路口的行人和车辆的异常状况。</p>
<p>交通部门还特别在意行人路口行为。他们主要想知道是否有行人不使用人行道。解决这个问题有很多方法。一半方法是检测处图像中的人行道，然后将人行道范围外的行人标为异常。</p>
<p>某路口异常行为<br>笔者使用了另外一种方法。笔者找了一个路口连续运行YOLO3识别目标物五个小时，然后将所有行人类别的图片坐标（矩形框四个角的像素坐标）提取出，计算每一个矩形框右下，左下像素坐标的平均值，然后将每一个矩形框转换成一个像素点，我们之所以使用左下，右下的坐标，是因为这两个坐标更加贴近地面，可以更好的代表地面上的人行道。下图中每一个红色点代表这个小时内所有行人的位置。这份数据可以揭示行人过马路的规律。由于大多数人都使用人行道过马路，图中可以看到红点都聚集在人行道附近。反之，图片中的其他位置没有红点。</p>
<p>原始路口抓拍图</p>
<p>红点代表行人的历史位置<br>为了将图像中高密度和低密度的红点分开，笔者使用了DBSCAN分析算法。DBSCAN更具点的空间分布以及每个点周围的噪声情况来识别高密度点聚类。DBSCAN还会将一些距离点聚类区域较远的点标为outlier。下图就是使用DBSCAN标记出了不在人行道区域的行人。</p>
<p>未使用人行道的行人 1</p>
<p>未使用人行道的行人 2<br>结论以及展望<br>本文，笔者介绍了GeoAI团队开发的交通路况监测云解决方案。该解决方案可以1）访问获取实时视频数据，2）使用AWS上的YOLO3模型实时识别小汽车，巴士，卡车，摩托车，以及行人，3）将YOLO3的结果发送到AWS上面的GeoEvent服务，在Dashboard应用上会展示路况，并且使用大数据库中的历史数据进行分析，4）根据目标物的数量来分析异常事件，例如监测处于危险位置的行人。GIS在展示相机地理位置以及实时路况起到了关键的作用。未来我们还会基于此方案进行目标追踪，测速，统计车道流量等。</p>
<p>致谢以及参考文献<br>感谢Daniel Wilson配置AWS以及S3图片云存储，让整个流程快了10倍。感谢Joel McCune配置的Dashboard应用。感谢RJ Sunderman 在ArcGIS GeoEvent Server上的帮助，感谢Alberto Nieto联系交通部门启动了这个项目，使得我们可以将YOLO3，ArcGIS GeoEvent Server，AWS添加到Alberto之前的成果中去，实现实时云处理。最后感谢Mark Carlson配置了ArcGIS GeoEvent Server，以及AWS的深度学习镜像。我们还将这个解决方案复制到了Azure上面。如果你有疑问，或者有意向合作，欢迎联系我们。</p>
<h1 id="1-https-developers-arcgis-com-python2-https-aws-amazon-com-machine-learning-amis3-http-www-arcgis-com-index-html4-http-www-trafficland-com5-https-github-com-tzutalin-labelImg6-https-arxiv-org-abs-1506-02640https-arxiv-org-abs-1612-08242https-arxiv-org-abs-1804-02767https-lilianweng-github-io-lil-log-2018-12-27-object-detection-part-4-html-yolo-you-only-look-oncehttps-towardsdatascience-com-yolo-v3-object-detection-53fb7d3bfe6b7-https-github-com-qqwweee-keras-yolo38-https-enterprise-arcgis-com-en-geoevent-latest-get-started-a-quick-tour-of-geoevent-server-htm9-https-enterprise-arcgis-com-en-geoevent-latest-administer-managing-big-data-stores-htm10-http-desktop-arcgis-com-en-arcmap-10-3-analyze-modelbuilder-what-is-modelbuilder-htm11-https-www-esri-com-en-us-arcgis-products-operations-dashboard-overview"><a href="#1-https-developers-arcgis-com-python2-https-aws-amazon-com-machine-learning-amis3-http-www-arcgis-com-index-html4-http-www-trafficland-com5-https-github-com-tzutalin-labelImg6-https-arxiv-org-abs-1506-02640https-arxiv-org-abs-1612-08242https-arxiv-org-abs-1804-02767https-lilianweng-github-io-lil-log-2018-12-27-object-detection-part-4-html-yolo-you-only-look-oncehttps-towardsdatascience-com-yolo-v3-object-detection-53fb7d3bfe6b7-https-github-com-qqwweee-keras-yolo38-https-enterprise-arcgis-com-en-geoevent-latest-get-started-a-quick-tour-of-geoevent-server-htm9-https-enterprise-arcgis-com-en-geoevent-latest-administer-managing-big-data-stores-htm10-http-desktop-arcgis-com-en-arcmap-10-3-analyze-modelbuilder-what-is-modelbuilder-htm11-https-www-esri-com-en-us-arcgis-products-operations-dashboard-overview" class="headerlink" title="1] https://developers.arcgis.com/python2] https://aws.amazon.com/machine-learning/amis3] http://www.arcgis.com/index.html4] http://www.trafficland.com5] https://github.com/tzutalin/labelImg6] https://arxiv.org/abs/1506.02640https://arxiv.org/abs/1612.08242https://arxiv.org/abs/1804.02767https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html#yolo-you-only-look-oncehttps://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b7] https://github.com/qqwweee/keras-yolo38] https://enterprise.arcgis.com/en/geoevent/latest/get-started/a-quick-tour-of-geoevent-server.htm9] https://enterprise.arcgis.com/en/geoevent/latest/administer/managing-big-data-stores.htm10] http://desktop.arcgis.com/en/arcmap/10.3/analyze/modelbuilder/what-is-modelbuilder.htm11] https://www.esri.com/en-us/arcgis/products/operations-dashboard/overview"></a>1] <a target="_blank" rel="noopener" href="https://developers.arcgis.com/python">https://developers.arcgis.com/python</a><br>2] <a target="_blank" rel="noopener" href="https://aws.amazon.com/machine-learning/amis">https://aws.amazon.com/machine-learning/amis</a><br>3] <a target="_blank" rel="noopener" href="http://www.arcgis.com/index.html">http://www.arcgis.com/index.html</a><br>4] <a target="_blank" rel="noopener" href="http://www.trafficland.com/">http://www.trafficland.com</a><br>5] <a target="_blank" rel="noopener" href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a><br>6] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.02640https://arxiv.org/abs/1612.08242https://arxiv.org/abs/1804.02767https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html#yolo-you-only-look-oncehttps://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b">https://arxiv.org/abs/1506.02640https://arxiv.org/abs/1612.08242https://arxiv.org/abs/1804.02767https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html#yolo-you-only-look-oncehttps://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b</a><br>7] <a target="_blank" rel="noopener" href="https://github.com/qqwweee/keras-yolo3">https://github.com/qqwweee/keras-yolo3</a><br>8] <a target="_blank" rel="noopener" href="https://enterprise.arcgis.com/en/geoevent/latest/get-started/a-quick-tour-of-geoevent-server.htm">https://enterprise.arcgis.com/en/geoevent/latest/get-started/a-quick-tour-of-geoevent-server.htm</a><br>9] <a target="_blank" rel="noopener" href="https://enterprise.arcgis.com/en/geoevent/latest/administer/managing-big-data-stores.htm">https://enterprise.arcgis.com/en/geoevent/latest/administer/managing-big-data-stores.htm</a><br>10] <a target="_blank" rel="noopener" href="http://desktop.arcgis.com/en/arcmap/10.3/analyze/modelbuilder/what-is-modelbuilder.htm">http://desktop.arcgis.com/en/arcmap/10.3/analyze/modelbuilder/what-is-modelbuilder.htm</a><br>11] <a target="_blank" rel="noopener" href="https://www.esri.com/en-us/arcgis/products/operations-dashboard/overview">https://www.esri.com/en-us/arcgis/products/operations-dashboard/overview</a></h1><p>原文链接：<a target="_blank" rel="noopener" href="https://medium.com/geoai/an-end-to-end-solution-on-the-cloud-to-monitor-traffic-flow-using-deep-learning-9dfdfd00b621">https://medium.com/geoai/an-end-to-end-solution-on-the-cloud-to-monitor-traffic-flow-using-deep-learning-9dfdfd00b621</a></p>
<p>本文将大致介绍如何结合监控视频流，ArcGIS，ArcGIS API for API，AWS等技术来监测车流量。</p>
<p>目录：</p>
<p>交通治理以及研究问题描述<br>实时视频流以及数据标注<br>目标检测：在AWS上训练YOLO3模型<br>流程架构<br>使用Dashboard应用实时监测路况<br>基于历史数据的异常行为监测<br>结论以及展望<br>致谢以及参考文献<br>交通治理以及问题研究描述<br>车流量是监测城市环境状态的一个重要要素。控制道路上车流量是一个非常基本的需求。在一些大城市，通常使用监控相机监测繁忙的道路，高速公路，以及十字路口。交通局工作人员通常对事故，路面覆盖物（雨，冰，雪），路面犯罪，抛锚，超速，拥堵，行人数量等信息感兴趣。监控相机可以帮助更好治理路况维持公共安全。国家高速公路安全管理局的一项研究表明，36%的碰撞事故都发生在道路交汇处。因此，十字路口时城市交通拥堵的罪魁祸首，也是交管中心重点监测对象。为了监测和管理路况，交通十字路口通常安装了许多相机。监测相机可以时固定，也可以是可遥控的PTZ相机。</p>
<p>监控抓拍图-昼</p>
<p>监控抓拍图-夜<br>于是，华盛顿区域的交通部门需要Esri定制一个云解决方案，方案需要满足以下需求：1）监测110个交通路口的路况（小汽车，公交，卡车，摩托车，行人），并且使用GIS将其可视化。2）监测路口流量异常。3）监测处在危险区域的行人。这个解决方案不仅需要监控相机，还需要将空间数据和深度学习框架结合。</p>
<p>本文将介绍，如何使用ArcGIS，ArcGIS API for Pyhon，AWS以及Keras深度学习框架实现这个解决方案。解决方案是使用AWS环境中的GPU来加速实时处理视频流，从而进行模型训练和推断预测。ArcGIS API for Python将空间信息如视频流的位置与深度学习框架结合，并且使用ArcGIS Enterprise将时间信息一同保存。</p>
<p>实时视频流以及数据标注<br>深度学习模型需要大量的训练数据。作者通过Traffic Land的REST API服务获取华盛顿111个路口的实视监控视频。作者使用Python代码，从TrafficLand服务上面获取了这111个监控相机的1000多张日夜抓拍图。作者将这些训练数据图片放到一个文件夹里面，然后使用LabelImg的工具人工标注图片中的目标物。最后将标注信息导出为txt文件，txt文件可以被绝大多数的目标检测算法使用。</p>
<p>使用LabelImg软件标注<br>目标检测：在AWS上训练YOLO3模型<br>我们的目的是从实时的视频中识别目标物。YOLO是一个目标检测很火的算法，该算法在实时应用中的精准度十分的高。YOLO可以生成目标物在图片中的位置，并且告诉用户该目标物的类别。YOLO只需要在网络中进行一次前向衍生就能够提供预测。早些版本的YOLO如YOLO2无法识别细小的目标物，因为YOLO2的计算层降低了输入图片的分辨率。除此之外，YOLO2还缺少一些牛叉的技术，如residual blocks，skip connections 以及 upsampling。YOLO3增加计算层以及YOLO2中那些没有的牛叉的功能。YOLO3算法在模型里面3个不同的位置，对尺寸不同的要素图运用1*1的识别窗口来实现目标检测。关于YOLO的原理有很多的博客和资源，这里不不做赘述。你可以在这些参考文献里了解YOLO的原理。</p>
<p>YOLO模型<br>来自111个监控相机的1000多张带有标签的日夜抓拍图将被用作训练数据，在AWS上面训练YOLO3模型。笔者使用了AWS的EC2实例，EC2实例提供专门用来深度学习的镜像，这些镜像通常预装自带了Tensorflow，PyTorch，Keras等框架，可以用于训练复杂的深度学习模型。笔者使用了预训练的YOLO3模型以及转移学习技术。随后作者对比了预测结果和实际结果。训练模型的IOU达95%。笔者使用了现成的开源Github代码训练YOLO3 模型。</p>
<p>流程架构<br>为了在AWS上面搭建一个实时流程，我们使用了如下架构来实现路况监测：1）我们使用并行处理来加速从TrafficLand REST API取视频流程的过程。2）紧接着，抓拍图被传到AWS EC2实例上的YOLO3模型里面。YOLO3对每一个片中的目标识别并且分类。总体上使用一个NVIDIA Tesla K80 GPU，我们可以在10内完成111张图片的抓取以及预测。3）最后我们将YOLO3的预测结果传到AWS的GeoEvent中的大数据库中，从而可以在大屏幕上对每一类数据进行可视化。每一个监控相机的相关照片都保存在S3 bucket云存储中。</p>
<p>流程架构设计图<br>我们的IT团队在AWS配置好了深度学习EC2实例以及ArcGIS GeoEvent Server。GeoEvent Server将实时的流数据与带有位置数据的要素类或大数据库相结合。为了将GeoEvent Server和EC2实例上的YOLO3深度学习模型相连接，笔者在GeoEvent服务中配置了输入连接器，处理器，输出连接器。GeoEvent服务可以通过用户图形界面创建，类似Model Builder的创建方法。</p>
<p>GeoEvent输入连接器定义了来自YOLO3模型的事件数据结构，并且把事件数据传送给GeoEvent处理器。如果你的数据结构有差异，GeoEvent将无法读取事件数据。GeoEvent中有好几种常用格式（文本，RSS，ESRI要素JSON，JSON）和协议（系统文件，HTTP，TCP，UDP，WebSocket，ESRI要素服务）的输入连接器。建立输入连接器是，用户要新建一个GeoEvent Definition，GeoEvent Definition里面定义了事件数据的数据结构。下图分别展示了GeoJSON格式的GeoEvent Definition，和RestAPI的数据通信渠道。因此，每一个相机的YOLO3模型的输出结果都会使用相机位置信息转换成GeoJSON。</p>
<p>GeoEvent Definition</p>
<p>GeoEvent Input Connector<br>GeoEvent处理器是GeoEvent服务里面的一个可配置元素。GeoEvent服务提供基于事件数据的分析，比如对事件数据进行识别，对事件数据进行扩充。由于我们的流程没有对事件数据做任何处理，因此我们的流程中将不会使用任何GeoEvent处理器。</p>
<p>GeoEvent输出连接器的作用是将GeoEvent数据重新转成符合各种协议的流数据。我们配置了两个GeoEvent服务：1）一个实时GeoEvent服务，用于获取实时数据以及大屏可视化。2）一个历史GeoEvent服务，用于保存历史数据要素类可以后续用于异常分析。这两个服务的不同之处在于，实时服务只保存最新的111条记录，然而历史服务会保存之前所有生成的记录。我们可以算一下按每秒111条记录的速率，一天数据量将达到9.6百万（111相机<em>24小时</em>60分*60秒）。</p>
<p>Update a Feature Ouput Connector</p>
<p>Add a Feature Output Connector<br>使用Dashboard应用实时监测路况<br>我们使用了Dashboard应用来实现自动化监测实时交通路况。Dashboard应用展示了111个实时视频流的位置，以及每个路口各种车型的计数。Dashboard的数据来自GeoEvent服务生成的要素类。用户通过Dashboard可以判断华盛顿区域行人或者车辆拥堵的具体位置。用户要可以看到每个监控相机的实时画面。下图展示了Dashboard应用的界面。Dashboard根据用户当前浏览的地图区域更新左侧的统计数据。</p>
<p>Dashboard应用</p>
<p>查询某一个路口<br>基于历史数据的异常行为监测<br>交通部门还想知道每一种车型和行人在路口的动态流量是如何的。为了解决这个问题，我们在一个礼拜后使用历史GeoEvent服务生成的数据来计算每一种车型和行人每天每一分钟的流量状况。我们简单计算一下，会有约1百万种可能的组合（111相机<em>7天</em>24小时*60分钟）。你可以把它比作一个异常监测的查询表。我们将每一种车型的计数与历史技术做比较，如果计数高于历史计数30%，那么我们称为流量异常，并且将异常展现在地图上。我们将异常事件写进一个单独的要素类里面。下图展示了某个路口的行人和车辆的异常状况。</p>
<p>交通部门还特别在意行人路口行为。他们主要想知道是否有行人不使用人行道。解决这个问题有很多方法。一半方法是检测处图像中的人行道，然后将人行道范围外的行人标为异常。</p>
<p>某路口异常行为<br>笔者使用了另外一种方法。笔者找了一个路口连续运行YOLO3识别目标物五个小时，然后将所有行人类别的图片坐标（矩形框四个角的像素坐标）提取出，计算每一个矩形框右下，左下像素坐标的平均值，然后将每一个矩形框转换成一个像素点，我们之所以使用左下，右下的坐标，是因为这两个坐标更加贴近地面，可以更好的代表地面上的人行道。下图中每一个红色点代表这个小时内所有行人的位置。这份数据可以揭示行人过马路的规律。由于大多数人都使用人行道过马路，图中可以看到红点都聚集在人行道附近。反之，图片中的其他位置没有红点。</p>
<p>原始路口抓拍图</p>
<p>红点代表行人的历史位置<br>为了将图像中高密度和低密度的红点分开，笔者使用了DBSCAN分析算法。DBSCAN更具点的空间分布以及每个点周围的噪声情况来识别高密度点聚类。DBSCAN还会将一些距离点聚类区域较远的点标为outlier。下图就是使用DBSCAN标记出了不在人行道区域的行人。</p>
<p>未使用人行道的行人 1</p>
<p>未使用人行道的行人 2<br>结论以及展望<br>本文，笔者介绍了GeoAI团队开发的交通路况监测云解决方案。该解决方案可以1）访问获取实时视频数据，2）使用AWS上的YOLO3模型实时识别小汽车，巴士，卡车，摩托车，以及行人，3）将YOLO3的结果发送到AWS上面的GeoEvent服务，在Dashboard应用上会展示路况，并且使用大数据库中的历史数据进行分析，4）根据目标物的数量来分析异常事件，例如监测处于危险位置的行人。GIS在展示相机地理位置以及实时路况起到了关键的作用。未来我们还会基于此方案进行目标追踪，测速，统计车道流量等。</p>
<p>致谢以及参考文献<br>感谢Daniel Wilson配置AWS以及S3图片云存储，让整个流程快了10倍。感谢Joel McCune配置的Dashboard应用。感谢RJ Sunderman 在ArcGIS GeoEvent Server上的帮助，感谢Alberto Nieto联系交通部门启动了这个项目，使得我们可以将YOLO3，ArcGIS GeoEvent Server，AWS添加到Alberto之前的成果中去，实现实时云处理。最后感谢Mark Carlson配置了ArcGIS GeoEvent Server，以及AWS的深度学习镜像。我们还将这个解决方案复制到了Azure上面。如果你有疑问，或者有意向合作，欢迎联系我们。</p>
<p>1] <a target="_blank" rel="noopener" href="https://developers.arcgis.com/python">https://developers.arcgis.com/python</a><br>2] <a target="_blank" rel="noopener" href="https://aws.amazon.com/machine-learning/amis">https://aws.amazon.com/machine-learning/amis</a><br>3] <a target="_blank" rel="noopener" href="http://www.arcgis.com/index.html">http://www.arcgis.com/index.html</a><br>4] <a target="_blank" rel="noopener" href="http://www.trafficland.com/">http://www.trafficland.com</a><br>5] <a target="_blank" rel="noopener" href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a><br>6] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.02640https://arxiv.org/abs/1612.08242https://arxiv.org/abs/1804.02767https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html#yolo-you-only-look-oncehttps://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b">https://arxiv.org/abs/1506.02640https://arxiv.org/abs/1612.08242https://arxiv.org/abs/1804.02767https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html#yolo-you-only-look-oncehttps://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b</a><br>7] <a target="_blank" rel="noopener" href="https://github.com/qqwweee/keras-yolo3">https://github.com/qqwweee/keras-yolo3</a><br>8] <a target="_blank" rel="noopener" href="https://enterprise.arcgis.com/en/geoevent/latest/get-started/a-quick-tour-of-geoevent-server.htm">https://enterprise.arcgis.com/en/geoevent/latest/get-started/a-quick-tour-of-geoevent-server.htm</a><br>9] <a target="_blank" rel="noopener" href="https://enterprise.arcgis.com/en/geoevent/latest/administer/managing-big-data-stores.htm">https://enterprise.arcgis.com/en/geoevent/latest/administer/managing-big-data-stores.htm</a><br>10] <a target="_blank" rel="noopener" href="http://desktop.arcgis.com/en/arcmap/10.3/analyze/modelbuilder/what-is-modelbuilder.htm">http://desktop.arcgis.com/en/arcmap/10.3/analyze/modelbuilder/what-is-modelbuilder.htm</a><br>11] <a target="_blank" rel="noopener" href="https://www.esri.com/en-us/arcgis/products/operations-dashboard/overview">https://www.esri.com/en-us/arcgis/products/operations-dashboard/overview</a></p>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>7700261 (first commit)<br>12] <a target="_blank" rel="noopener" href="https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/densitybasedclustering.htm">https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/densitybasedclustering.htm</a></p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-trafficReg/" data-id="cll50ezwu000axpbia4dh2z0k" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-Perceptron" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-Perceptron/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.586Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h5 id="单层感知机"><a href="#单层感知机" class="headerlink" title="单层感知机"></a>单层感知机</h5><p><img src="https://raw.githubusercontent.com/ebxeax/images/main/singleLayerPerceptron.png" alt="slpmodel"><br>$$<br>\begin{aligned}<br>&amp; y &#x3D; XW + b \<br>&amp; y &#x3D; \sum x_i*w_i+b\<br>\end{aligned}<br>$$</p>
<h5 id="Derivative"><a href="#Derivative" class="headerlink" title="Derivative"></a>Derivative</h5><p>$$<br>\begin{aligned}<br>&amp;E&#x3D;\frac{1}{2}(O^1_0-t)^2\<br>&amp;\frac{\delta E}{\delta W_{j0}}&#x3D;(O_0-t)\frac{\delta O_0}{\delta w_{j0}}\<br>&amp;&#x3D;(O_0-t)\frac{\delta O_0}{\delta w_{j0}}\<br>&amp;&#x3D;(O_0-t)\delta(x_0)(1-\delta(x_0))\frac{\delta x_0^1}{\delta w_j^0}\<br>&amp;&#x3D;(O_0-t)O_0(1-O_0)\frac{\delta x_0^1}{\delta w_j^0}\<br>&amp;&#x3D;(O_0-t)O_0(1-O_0)x_j^0<br>\end{aligned}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch,torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">w = torch.randn(<span class="number">1</span>, <span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">o = torch.sigmoid(x@w.t())</span><br><span class="line">o.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([1, 1])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = F.mse_loss(torch.ones(<span class="number">1</span>, <span class="number">1</span>), o)</span><br><span class="line">loss.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss.backward()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w.grad</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-0.1801,  0.1923,  0.2480, -0.0919,  0.1487,  0.0196, -0.1588, -0.1652,
          0.3811, -0.2290]])
</code></pre>
<h5 id="Multi-output-Perceptron"><a href="#Multi-output-Perceptron" class="headerlink" title="Multi-output Perceptron"></a>Multi-output Perceptron</h5><p><img src="https://raw.githubusercontent.com/ebxeax/images/main/Multi-outputPerceptron.png" alt="mop"></p>
<h5 id="Derivative-1"><a href="#Derivative-1" class="headerlink" title="Derivative"></a>Derivative</h5><p>$$<br>\begin{aligned}<br>&amp;E&#x3D;\frac{1}{2}(O^1_i-t)^2\<br>&amp;\frac{\delta E}{\delta W_{jk}}&#x3D;(O_k-t_k)\frac{\delta O_k}{\delta w_{jk}}\<br>&amp;&#x3D;(O_k-t)\frac{\delta O_0}{\delta w_{j0}}\<br>&amp;&#x3D;(O_k-t)\delta(x_0)(1-\delta(x_0))\frac{\delta x_0^1}{\delta w_j^0}\<br>&amp;&#x3D;(O_k-t)O_0(1-O_0)\frac{\delta x_0^1}{\delta w_j^0}\<br>&amp;&#x3D;(O_k-t)O_0(1-O_0)x_j^0<br>\end{aligned}<br>$$</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-Perceptron/" data-id="cll50ezwj0006xpbi87095x82" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-Minima" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-Minima/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.552Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p>
<h4 id="Minima"><a href="#Minima" class="headerlink" title="Minima"></a>Minima</h4><p>$$<br>f(x,y)&#x3D;(x^2+y-11)^2+(x+y^2-7)^2<br>$$<br><img src="https://raw.githubusercontent.com/ebxeax/images/main/himff.png" alt="himff"><br>$$<br>f(3.0, 2.0)&#x3D;0.0\<br>f(-2.8505118, 3.131312)&#x3D;0.0\<br>f(-3.779310, -3.283186)&#x3D;0.0\<br>f(3.584428, -1.84126)&#x3D;0.0\<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np, torch, torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">himmelblau</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (x[<span class="number">0</span>] ** <span class="number">2</span> + x[<span class="number">1</span>] - <span class="number">11</span>) ** <span class="number">2</span> + (x[<span class="number">0</span>] + x[<span class="number">1</span>] ** <span class="number">2</span> - <span class="number">7</span>) ** <span class="number">2</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">y = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x, y range:&quot;</span>, x.shape, y.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x, y range: (120,) (120,)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X, Y maps:&quot;</span>, X.shape, Y.shape)</span><br><span class="line">Z = himmelblau([X, Y])</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X, Y maps: (120, 120) (120, 120)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(<span class="string">&#x27;himmelblau&#x27;</span>)</span><br><span class="line">ax = fig.gca(projection = <span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X, Y, Z)</span><br><span class="line">ax.view_init(<span class="number">60</span>, -<span class="number">30</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gradient Descent</span></span><br><span class="line"><span class="comment">#[1., 0] [-4, 0.] [4, 0.]</span></span><br><span class="line">x = torch.tensor([<span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">opt = torch.optim.Adam([x], lr=<span class="number">1e-3</span>)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20001</span>):</span><br><span class="line">    pred = himmelblau(x)</span><br><span class="line">    opt.zero_grad()</span><br><span class="line">    pred.backward()</span><br><span class="line">    opt.step()</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;step &#123;&#125;: x = &#123;&#125;, f(x) = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(step, x.tolist(), pred.item()))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">step 0: x = [0.0009999999310821295, 0.0009999999310821295], f(x) = 170.0</span><br><span class="line">step 2000: x = [2.3331806659698486, 1.9540694952011108], f(x) = 13.730916023254395</span><br><span class="line">step 4000: x = [2.9820079803466797, 2.0270984172821045], f(x) = 0.014858869835734367</span><br><span class="line">step 6000: x = [2.999983549118042, 2.0000221729278564], f(x) = 1.1074007488787174e-08</span><br><span class="line">step 8000: x = [2.9999938011169434, 2.0000083446502686], f(x) = 1.5572823031106964e-09</span><br><span class="line">step 10000: x = [2.999997854232788, 2.000002861022949], f(x) = 1.8189894035458565e-10</span><br><span class="line">step 12000: x = [2.9999992847442627, 2.0000009536743164], f(x) = 1.6370904631912708e-11</span><br><span class="line">step 14000: x = [2.999999761581421, 2.000000238418579], f(x) = 1.8189894035458565e-12</span><br><span class="line">step 16000: x = [3.0, 2.0], f(x) = 0.0</span><br><span class="line">step 18000: x = [3.0, 2.0], f(x) = 0.0</span><br><span class="line">step 20000: x = [3.0, 2.0], f(x) = 0.0</span><br><span class="line">=======</span><br><span class="line">#### Minima  </span><br><span class="line">$$</span><br><span class="line">f(x,y)=(x^2+y-11)^2+(x+y^2-7)^2</span><br><span class="line">$$</span><br><span class="line">![himff](https://raw.githubusercontent.com/ebxeax/images/main/himff.png)</span><br><span class="line">$$</span><br><span class="line">f(3.0, 2.0)=0.0\\</span><br><span class="line">f(-2.8505118, 3.131312)=0.0\\</span><br><span class="line">f(-3.779310, -3.283186)=0.0\\</span><br><span class="line">f(3.584428, -1.84126)=0.0\\</span><br><span class="line">$$</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">%matplotlib inline</span><br><span class="line">import numpy as np, torch, torch.nn.functional as F</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">himmelblau</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (x[<span class="number">0</span>] ** <span class="number">2</span> + x[<span class="number">1</span>] - <span class="number">11</span>) ** <span class="number">2</span> + (x[<span class="number">0</span>] + x[<span class="number">1</span>] ** <span class="number">2</span> - <span class="number">7</span>) ** <span class="number">2</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">y = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x, y range:&quot;</span>, x.shape, y.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x, y range: (120,) (120,)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X, Y maps:&quot;</span>, X.shape, Y.shape)</span><br><span class="line">Z = himmelblau([X, Y])</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X, Y maps: (120, 120) (120, 120)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(<span class="string">&#x27;himmelblau&#x27;</span>)</span><br><span class="line">ax = fig.gca(projection = <span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X, Y, Z)</span><br><span class="line">ax.view_init(<span class="number">60</span>, -<span class="number">30</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gradient Descent</span></span><br><span class="line"><span class="comment">#[1., 0] [-4, 0.] [4, 0.]</span></span><br><span class="line">x = torch.tensor([<span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">opt = torch.optim.Adam([x], lr=<span class="number">1e-3</span>)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20001</span>):</span><br><span class="line">    pred = himmelblau(x)</span><br><span class="line">    opt.zero_grad()</span><br><span class="line">    pred.backward()</span><br><span class="line">    opt.step()</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;step &#123;&#125;: x = &#123;&#125;, f(x) = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(step, x.tolist(), pred.item()))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">step 0: x = [0.0009999999310821295, 0.0009999999310821295], f(x) = 170.0</span><br><span class="line">step 2000: x = [2.3331806659698486, 1.9540694952011108], f(x) = 13.730916023254395</span><br><span class="line">step 4000: x = [2.9820079803466797, 2.0270984172821045], f(x) = 0.014858869835734367</span><br><span class="line">step 6000: x = [2.999983549118042, 2.0000221729278564], f(x) = 1.1074007488787174e-08</span><br><span class="line">step 8000: x = [2.9999938011169434, 2.0000083446502686], f(x) = 1.5572823031106964e-09</span><br><span class="line">step 10000: x = [2.999997854232788, 2.000002861022949], f(x) = 1.8189894035458565e-10</span><br><span class="line">step 12000: x = [2.9999992847442627, 2.0000009536743164], f(x) = 1.6370904631912708e-11</span><br><span class="line">step 14000: x = [2.999999761581421, 2.000000238418579], f(x) = 1.8189894035458565e-12</span><br><span class="line">step 16000: x = [3.0, 2.0], f(x) = 0.0</span><br><span class="line">step 18000: x = [3.0, 2.0], f(x) = 0.0</span><br><span class="line">step 20000: x = [3.0, 2.0], f(x) = 0.0</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt; 7700261 (first commit)</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-Minima/" data-id="cll50ezwl0007xpbif49j4wr6" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-cnn原则2" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-cnn%E5%8E%9F%E5%88%992/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.523Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="原则-2-局部性"><a href="#原则-2-局部性" class="headerlink" title="原则#2 - 局部性"></a>原则#2 - 局部性</h1><p>$$<br>h_{i,j}&#x3D;\sum{a,b}v_{a,b}x_{i+a,j+b}<br>$$</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-cnn%E5%8E%9F%E5%88%992/" data-id="cll50ezwr0009xpbi44c05sw9" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-021gpu_accelerated" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-021gpu_accelerated/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.493Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">import</span>  torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span>  torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span>  torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span>    torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="comment">#超参数</span></span><br><span class="line">batch_size=<span class="number">200</span></span><br><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line">epochs=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取训练数据</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,          <span class="comment">#train=True则得到的是训练集</span></span><br><span class="line">                   transform=transforms.Compose([                 <span class="comment">#transform进行数据预处理</span></span><br><span class="line">                       transforms.ToTensor(),                     <span class="comment">#转成Tensor类型的数据</span></span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,)) <span class="comment">#进行数据标准化(减去均值除以方差)</span></span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)                          <span class="comment">#按batch_size分出一个batch维度在最前面,shuffle=True打乱顺序</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取测试数据</span></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">    ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(         <span class="comment">#定义网络的每一层，nn.ReLU可以换成其他激活函数，比如nn.LeakyReLU()</span></span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">10</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = MLP()</span><br><span class="line"><span class="comment">#定义sgd优化器,指明优化参数、学习率，net.parameters()得到这个类所定义的网络的参数[[w1,b1,w2,b2,...]</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=learning_rate)</span><br><span class="line">criteon = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)          <span class="comment">#将二维的图片数据摊平[样本数,784]</span></span><br><span class="line"></span><br><span class="line">        logits = net(data)                   <span class="comment">#前向传播</span></span><br><span class="line">        loss = criteon(logits, target)       <span class="comment">#nn.CrossEntropyLoss()自带Softmax</span></span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()                <span class="comment">#梯度信息清空</span></span><br><span class="line">        loss.backward()                      <span class="comment">#反向传播获取梯度</span></span><br><span class="line">        optimizer.step()                     <span class="comment">#优化器更新</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:             <span class="comment">#每100个batch输出一次信息</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                       <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span>                                         <span class="comment">#correct记录正确分类的样本数</span></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>)</span><br><span class="line">        logits = net(data)</span><br><span class="line">        test_loss += criteon(logits, target).item()     <span class="comment">#其实就是criteon(logits, target)的值，标量</span></span><br><span class="line"></span><br><span class="line">        pred = logits.data.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>]                <span class="comment">#也可以写成pred=logits.argmax(dim=1)</span></span><br><span class="line">        correct += pred.eq(target.data).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br></pre></td></tr></table></figure>

<pre><code>C:\Users\ygx79\AppData\Local\Programs\Python\Python37\lib\site-packages\torchvision\io\image.py:11: UserWarning: Failed to load image Python extension: [WinError 126] 找不到指定的模块。
  warn(f&quot;Failed to load image Python extension: &#123;e&#125;&quot;)


Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data\MNIST\raw\train-images-idx3-ubyte.gz


9913344it [09:45, 16922.35it/s]                              


Extracting ../data\MNIST\raw\train-images-idx3-ubyte.gz to ../data\MNIST\raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data\MNIST\raw\train-labels-idx1-ubyte.gz


29696it [00:00, 112126.01it/s]                          


Extracting ../data\MNIST\raw\train-labels-idx1-ubyte.gz to ../data\MNIST\raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data\MNIST\raw\t10k-images-idx3-ubyte.gz


1649664it [00:06, 236143.14it/s]                             


Extracting ../data\MNIST\raw\t10k-images-idx3-ubyte.gz to ../data\MNIST\raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data\MNIST\raw\t10k-labels-idx1-ubyte.gz


5120it [00:00, ?it/s]                   


Extracting ../data\MNIST\raw\t10k-labels-idx1-ubyte.gz to ../data\MNIST\raw

Train Epoch: 0 [0/60000 (0%)]	Loss: 2.307192
Train Epoch: 0 [20000/60000 (33%)]	Loss: 2.138816
Train Epoch: 0 [40000/60000 (67%)]	Loss: 1.768016

Test set: Average loss: 0.0070, Accuracy: 6058/10000 (61%)

Train Epoch: 1 [0/60000 (0%)]	Loss: 1.505597
Train Epoch: 1 [20000/60000 (33%)]	Loss: 1.149395
Train Epoch: 1 [40000/60000 (67%)]	Loss: 1.039293

Test set: Average loss: 0.0047, Accuracy: 7143/10000 (71%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 1.061429
Train Epoch: 2 [20000/60000 (33%)]	Loss: 0.741140
Train Epoch: 2 [40000/60000 (67%)]	Loss: 0.901448

Test set: Average loss: 0.0041, Accuracy: 7299/10000 (73%)

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.809117
Train Epoch: 3 [20000/60000 (33%)]	Loss: 0.892138
Train Epoch: 3 [40000/60000 (67%)]	Loss: 0.659411

Test set: Average loss: 0.0030, Accuracy: 8170/10000 (82%)

Train Epoch: 4 [0/60000 (0%)]	Loss: 0.622007
Train Epoch: 4 [20000/60000 (33%)]	Loss: 0.592337
Train Epoch: 4 [40000/60000 (67%)]	Loss: 0.445400

Test set: Average loss: 0.0027, Accuracy: 8225/10000 (82%)

Train Epoch: 5 [0/60000 (0%)]	Loss: 0.519135
Train Epoch: 5 [20000/60000 (33%)]	Loss: 0.491247
Train Epoch: 5 [40000/60000 (67%)]	Loss: 0.562315

Test set: Average loss: 0.0026, Accuracy: 8295/10000 (83%)

Train Epoch: 6 [0/60000 (0%)]	Loss: 0.509583
Train Epoch: 6 [20000/60000 (33%)]	Loss: 0.553628
Train Epoch: 6 [40000/60000 (67%)]	Loss: 0.484189

Test set: Average loss: 0.0025, Accuracy: 8336/10000 (83%)

Train Epoch: 7 [0/60000 (0%)]	Loss: 0.619250
Train Epoch: 7 [20000/60000 (33%)]	Loss: 0.634936
Train Epoch: 7 [40000/60000 (67%)]	Loss: 0.440220

Test set: Average loss: 0.0024, Accuracy: 8370/10000 (84%)

Train Epoch: 8 [0/60000 (0%)]	Loss: 0.410350
Train Epoch: 8 [20000/60000 (33%)]	Loss: 0.460459
Train Epoch: 8 [40000/60000 (67%)]	Loss: 0.395150

Test set: Average loss: 0.0024, Accuracy: 8395/10000 (84%)

Train Epoch: 9 [0/60000 (0%)]	Loss: 0.515630
Train Epoch: 9 [20000/60000 (33%)]	Loss: 0.546718
Train Epoch: 9 [40000/60000 (67%)]	Loss: 0.496167

Test set: Average loss: 0.0023, Accuracy: 8433/10000 (84%)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">net = MLP().to(device)</span><br><span class="line"><span class="comment">#定义sgd优化器,指明优化参数、学习率，net.parameters()得到这个类所定义的网络的参数[[w1,b1,w2,b2,...]</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=learning_rate)</span><br><span class="line">criteon = nn.CrossEntropyLoss().to(device)</span><br></pre></td></tr></table></figure>

<h5 id="GPU-acc"><a href="#GPU-acc" class="headerlink" title="GPU acc"></a>GPU acc</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">import</span>  torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span>  torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span>  torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span>    torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="comment">#超参数</span></span><br><span class="line">batch_size=<span class="number">200</span></span><br><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line">epochs=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取训练数据</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,          <span class="comment">#train=True则得到的是训练集</span></span><br><span class="line">                   transform=transforms.Compose([                 <span class="comment">#transform进行数据预处理</span></span><br><span class="line">                       transforms.ToTensor(),                     <span class="comment">#转成Tensor类型的数据</span></span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,)) <span class="comment">#进行数据标准化(减去均值除以方差)</span></span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)                          <span class="comment">#按batch_size分出一个batch维度在最前面,shuffle=True打乱顺序</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取测试数据</span></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">    ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(         <span class="comment">#定义网络的每一层,</span></span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">10</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">net = MLP().to(device)</span><br><span class="line"><span class="comment">#定义sgd优化器,指明优化参数、学习率，net.parameters()得到这个类所定义的网络的参数[[w1,b1,w2,b2,...]</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=learning_rate)</span><br><span class="line">criteon = nn.CrossEntropyLoss().to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)          <span class="comment">#将二维的图片数据摊平[样本数,784]</span></span><br><span class="line">        data, target = data.to(device), target.cuda()</span><br><span class="line"></span><br><span class="line">        logits = net(data)               <span class="comment">#前向传播</span></span><br><span class="line">        loss = criteon(logits, target)       <span class="comment">#nn.CrossEntropyLoss()自带Softmax</span></span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()                <span class="comment">#梯度信息清空</span></span><br><span class="line">        loss.backward()                      <span class="comment">#反向传播获取梯度</span></span><br><span class="line">        optimizer.step()                     <span class="comment">#优化器更新</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:             <span class="comment">#每100个batch输出一次信息</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                       <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span>                                         <span class="comment">#correct记录正确分类的样本数</span></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>)</span><br><span class="line">        data, target = data.to(device), target.cuda()</span><br><span class="line"></span><br><span class="line">        logits = net(data)</span><br><span class="line">        test_loss += criteon(logits, target).item()     <span class="comment">#其实就是criteon(logits, target)的值，标量</span></span><br><span class="line"></span><br><span class="line">        pred = logits.data.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>]                <span class="comment">#也可以写成pred=logits.argmax(dim=1)</span></span><br><span class="line">        correct += pred.eq(target.data).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br></pre></td></tr></table></figure>

<pre><code>Train Epoch: 0 [0/60000 (0%)]	Loss: 2.291108
Train Epoch: 0 [20000/60000 (33%)]	Loss: 2.003711
Train Epoch: 0 [40000/60000 (67%)]	Loss: 1.419139

Test set: Average loss: 0.0038, Accuracy: 8229/10000 (82%)

Train Epoch: 1 [0/60000 (0%)]	Loss: 0.754257
Train Epoch: 1 [20000/60000 (33%)]	Loss: 0.655030
Train Epoch: 1 [40000/60000 (67%)]	Loss: 0.444529

Test set: Average loss: 0.0021, Accuracy: 8884/10000 (89%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.439030
Train Epoch: 2 [20000/60000 (33%)]	Loss: 0.355868
Train Epoch: 2 [40000/60000 (67%)]	Loss: 0.366360

Test set: Average loss: 0.0017, Accuracy: 9037/10000 (90%)

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.439010
Train Epoch: 3 [20000/60000 (33%)]	Loss: 0.344060
Train Epoch: 3 [40000/60000 (67%)]	Loss: 0.255032

Test set: Average loss: 0.0015, Accuracy: 9116/10000 (91%)

Train Epoch: 4 [0/60000 (0%)]	Loss: 0.331074
Train Epoch: 4 [20000/60000 (33%)]	Loss: 0.301065
Train Epoch: 4 [40000/60000 (67%)]	Loss: 0.276514

Test set: Average loss: 0.0014, Accuracy: 9169/10000 (92%)

Train Epoch: 5 [0/60000 (0%)]	Loss: 0.281249
Train Epoch: 5 [20000/60000 (33%)]	Loss: 0.316320
Train Epoch: 5 [40000/60000 (67%)]	Loss: 0.248902

Test set: Average loss: 0.0013, Accuracy: 9210/10000 (92%)

Train Epoch: 6 [0/60000 (0%)]	Loss: 0.317820
Train Epoch: 6 [20000/60000 (33%)]	Loss: 0.315888
Train Epoch: 6 [40000/60000 (67%)]	Loss: 0.302683

Test set: Average loss: 0.0013, Accuracy: 9258/10000 (93%)

Train Epoch: 7 [0/60000 (0%)]	Loss: 0.290187
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-021gpu_accelerated/" data-id="cll50ezwo0008xpbi38wv7txq" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-019cross_entropy" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-019cross_entropy/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.460Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h4><p>Uncetainly<br>measure of surprise<br>higher entropy &#x3D; less info<br>$$Entropy &#x3D; -\sum_i P(i)\log P(i)$$</p>
<h4 id="Lottery"><a href="#Lottery" class="headerlink" title="Lottery"></a>Lottery</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = torch.full([<span class="number">4</span>], <span class="number">1</span>/<span class="number">4.</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a * torch.log2(a)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([-0.5000, -0.5000, -0.5000, -0.5000])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-(a * torch.log2(a)).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>tensor(2.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.7</span>])</span><br><span class="line">-(a * torch.log2(a)).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>tensor(1.3568)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">0.001</span>, <span class="number">0.001</span>, <span class="number">0.001</span>, <span class="number">0.999</span>])</span><br><span class="line">-(a * torch.log2(a)).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>tensor(0.0313)
</code></pre>
<h4 id="Croos-Entropy"><a href="#Croos-Entropy" class="headerlink" title="Croos Entropy"></a>Croos Entropy</h4><p>$$<br>\begin{aligned}<br>&amp;H(p,q)&#x3D;-\sum p(x)\log q(x)\<br>&amp;H(p,q)&#x3D;H(p)+D_{KL}(p|q)\<br>\end{aligned}<br>$$</p>
<h5 id="P-Q"><a href="#P-Q" class="headerlink" title="P&#x3D;Q"></a>P&#x3D;Q</h5><p>cross Entropy &#x3D; Entropy</p>
<h5 id="for-one-hot-encoding"><a href="#for-one-hot-encoding" class="headerlink" title="for one-hot encoding"></a>for one-hot encoding</h5><p>entropy &#x3D; log1 &#x3D;0</p>
<h4 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h4><p>$$<br>\begin{aligned}<br>&amp;H(P,Q)&#x3D;-P(cat)\log Q(cat)-(1-P(cat))\log(1-Q(cat))\<br>&amp;P(dog)&#x3D;(1-P(cat))\<br>&amp;H(P,Q)&#x3D;-\sum_{i&#x3D;(cat,dog)}P(i)\log(Q(i))\<br>&amp;&#x3D;-P(cat)\log Q(cat)-P(dog)\log Q(dog)-(y\log(p)+(1-y)\log (1-p))\<br>\end{aligned}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-019cross_entropy/" data-id="cll50ezwg0005xpbidl535n7v" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-15-016chain_rules" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/09/2022-06-15-016chain_rules/" class="article-date">
  <time class="dt-published" datetime="2023-08-09T03:00:38.426Z" itemprop="datePublished">2023-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h5 id="Derivative-Rules"><a href="#Derivative-Rules" class="headerlink" title="Derivative Rules"></a>Derivative Rules</h5><p>$$<br>\begin{aligned}<br>&amp;\frac{\delta E}{\delta w^1_{jk}}&#x3D;\frac{\delta E}{\delta O_k^1}\frac{\delta O_k^1}{\delta w^1_{jk}}&#x3D;\frac{\delta E}{\delta O_k^2}\frac{\delta O_k^2}{\delta O_k^1}\frac{\delta O_k^1}{\delta w^1_{jk}}\<br>\end{aligned}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch, torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor(<span class="number">1.</span>)</span><br><span class="line">w1, w2 = torch.tensor(<span class="number">2.</span>, requires_grad=<span class="literal">True</span>), torch.tensor(<span class="number">2.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">b1, b2 = torch.tensor(<span class="number">1.</span>), torch.tensor(<span class="number">1.</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y1 = x * w1 + b1 </span><br><span class="line">y2 = y1 * w2 +b2 </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dy2_dy1 = torch.autograd.grad(y2, [y1], retain_graph=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">dy1_dw1 = torch.autograd.grad(y1, [w1], retain_graph=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">dy2_dw1 = torch.autograd.grad(y2, [w1], retain_graph=<span class="literal">True</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dy2_dy1 * dy1_dw1</span><br></pre></td></tr></table></figure>




<pre><code>tensor(2.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dy2_dw1</span><br></pre></td></tr></table></figure>




<pre><code>tensor(2.)
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ebxeax.github.io/2023/08/09/2022-06-15-016chain_rules/" data-id="cll50ezwc0004xpbi4ozc8lt2" data-title="" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/4/">&laquo; zurück</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/6/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Kategorien</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/interpreter-C/">interpreter C</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">二月 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/08/09/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/08/09/%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/08/09/%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8%C2%B7%E9%A1%B5%E5%BC%8F%C2%B7%E6%AE%B5%E5%BC%8F%C2%B7%E6%AE%B5%E9%A1%B5%E5%BC%8F/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/08/09/YOLO_001_from-CNN-to-YOLOv1/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/08/09/PCC_007_%E7%AC%AC%E4%B8%83%E7%AB%A0-I%E2%81%84O/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 ebx<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>